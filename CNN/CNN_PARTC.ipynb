{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL_21100313_PA3_PARTC.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LsYBVxYeLzD0"
      },
      "source": [
        "### Dataset\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5o3bGPcRI9Dx"
      },
      "source": [
        "RollNum:21100313\r\n",
        "Kaggle UserName: TK11"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YCnj0tV8LzD0"
      },
      "source": [
        "The dataset is divided into training set and testing set. The training set is labeled and contains 80 images for each class (Total 240 images). You have been given unlabeled test set and your task is to predict the class of each test image. The test set contain 853 images.<br>\r\n",
        "Some guidelines:<br>\r\n",
        "- You are free to extend or augment the training set.<br>\r\n",
        "- If you want, you can use a subset of training set as your validation set.<br>\r\n",
        "- You must not use the provided test set in any way except for final predictions.<br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HFy8QgUoLzD1",
        "outputId": "4cf62a4d-14c3-4909-ffec-226048fede9b"
      },
      "source": [
        "!git clone https://github.com/MMFa666/VehicleDataset.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'VehicleDataset'...\n",
            "remote: Enumerating objects: 1106, done.\u001b[K\n",
            "remote: Counting objects: 100% (1106/1106), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1100/1100), done.\u001b[K\n",
            "remote: Total 1106 (delta 4), reused 1103 (delta 4), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (1106/1106), 34.18 MiB | 44.19 MiB/s, done.\n",
            "Resolving deltas: 100% (4/4), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TqvJHT6SLzD3"
      },
      "source": [
        "### Models\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7uvxda3hLzD4"
      },
      "source": [
        "You can use anyone of the following models for this task. See the [documentation](https://www.tensorflow.org/api_docs/python/tf/keras/applications#functions) for more details.\r\n",
        "- VGG\r\n",
        "- ResNet\r\n",
        "- MobileNet\r\n",
        "- EfficientNet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u986aO4ILzD4"
      },
      "source": [
        "### LeaderBoard\r\n",
        "\r\n",
        "The goal here is to get the maximum performance on test set. For this purpose, we have created a competition on Kaggle where a leaderboard is maintained. You will upload your predictions for test set there and a score will be generated for you. You will be ranked based on your score. You can submit upto 20 times a day with maximum 300 submissions in total.\r\n",
        "\r\n",
        "This part will be evaluated based on your approach and your performance in LeaderBoard. Furthermore, the top student will receive a 5%, 2nd will receive 3% and 3rd will receive 1% bonus.\r\n",
        "\r\n",
        "You are allowed to the following to win:\r\n",
        "- Extend your chosen model as you like.\r\n",
        "- Extend the training set.\r\n",
        "- Augment the training set.\r\n",
        "- Play with hyperparameters.\r\n",
        "- Preprocess the data as you like.\r\n",
        "\r\n",
        "Competition link [here](https://www.kaggle.com/c/lums-cs437-hw3/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZnAwDNaBLzD5"
      },
      "source": [
        "### Tutuorial Example\r\n",
        "\r\n",
        "You are recommended to follow this [tutorial](https://www.tensorflow.org/tutorials/images/transfer_learning) for this task. All the hints and information required are available here and this task can be easily completed by following it. In this tutorial, they use MobileNet but as mentioned above you are free to use any of the abovementioned models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55DoRIEJLzD6"
      },
      "source": [
        "### Let The Games Begin!!!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0z9JMgb4LzD6"
      },
      "source": [
        "# make necessary imports here\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import numpy as np\r\n",
        "from pprint import pprint\r\n",
        "import os\r\n",
        "import keras\r\n",
        "import shutil\r\n",
        "from glob import glob\r\n",
        "from pprint import pprint\r\n",
        "import tensorflow as tf\r\n",
        "import cv2\r\n",
        "from tqdm.notebook import trange,tqdm\r\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Dropout, BatchNormalization, Input, LeakyReLU, Flatten, Dropout\r\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from skimage.transform import resize"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1FN9wRjRtlFp"
      },
      "source": [
        "def extract_label(filepath = None, datatype = None):\r\n",
        "  fs = filepath.split(\"/\")\r\n",
        "  if datatype == \"train\":\r\n",
        "    label = fs[4]\r\n",
        "  if datatype == \"test\":\r\n",
        "    label = fs[3]\r\n",
        "  return label\r\n",
        "\r\n",
        "def load_dataset(filepaths = None , datatype = None):\r\n",
        "  X = []\r\n",
        "  Y = []\r\n",
        "  labels={}\r\n",
        "  labels['qingqi']=[1,0,0]\r\n",
        "  labels['rickshaw']=[0,1,0]\r\n",
        "  labels['tanga']=[0,0,1]\r\n",
        "  for filepath in filepaths:\r\n",
        "    img = cv2.imread(filepath)\r\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\r\n",
        "    img = resize(img, input_shape, preserve_range=True)\r\n",
        "    X.append(img)\r\n",
        "    label  = extract_label(filepath = filepath, datatype = datatype)\r\n",
        "    y = labels[label]\r\n",
        "    Y.append(y)\r\n",
        "  return X,Y"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "il7nQpTuLzD8"
      },
      "source": [
        "# define hyperparameters\r\n",
        "batch_size = 32\r\n",
        "epochs = 400\r\n",
        "learning_rate = 0.00001\r\n",
        "input_shape = (200,200)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "REo242ulwo3B"
      },
      "source": [
        "training_dir = os.path.join(os.getcwd(),\"VehicleDataset\",\"train\")\r\n",
        "testing_dir = os.path.join(os.getcwd(),\"VehicleDataset\",\"test\")\r\n",
        "validation_dir =  os.path.join(os.getcwd(),\"VehicleDataset\",\"validation\")"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45_my8j-6vvT"
      },
      "source": [
        "\r\n",
        "if not os.path.isdir(validation_dir):\r\n",
        "  os.mkdir(validation_dir)\r\n",
        "qingqi_val_dir = os.path.join(validation_dir,\"qingqi\")\r\n",
        "rickshaw_val_dir = os.path.join(validation_dir,\"rickshaw\")\r\n",
        "tanga_val_dir = os.path.join(validation_dir,\"tanga\")\r\n",
        "if not os.path.isdir(qingqi_val_dir):\r\n",
        "  os.mkdir(qingqi_val_dir)\r\n",
        "if not os.path.isdir(rickshaw_val_dir):\r\n",
        "  os.mkdir(rickshaw_val_dir)\r\n",
        "if not os.path.isdir(tanga_val_dir):\r\n",
        "  os.mkdir(tanga_val_dir)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JqX3BxX1LzD9"
      },
      "source": [
        "# read and preprocess the training data and extract the labels. (If your training data is large then you can also use batch generator like done in PartB.)\r\n",
        "# print the shape x and y data\r\n",
        "# split into validation set if you desire\r\n",
        "training_paths =  []\r\n",
        "for filename in glob(os.path.join(training_dir,\"**\"),recursive=True):\r\n",
        "  filepath = filename.split(\"/\")\r\n",
        "  if len(filepath) == 6:\r\n",
        "    training_paths.append(filename)\r\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGPBUeOSs_Gi"
      },
      "source": [
        "testing_paths =  []\r\n",
        "for filename in glob(os.path.join(testing_dir,\"**\"),recursive=True):\r\n",
        "  filepath = filename.split(\"/\")\r\n",
        "  if len(filepath) == 5 and filepath[-1] != '':\r\n",
        "    testing_paths.append(filename)\r\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X6N3mxIE7whb",
        "outputId": "76f707de-8a45-4593-b277-a91bc03e7bab"
      },
      "source": [
        "train_paths,val_paths = train_test_split(training_paths,test_size = 0.1)\r\n",
        "for val_path in val_paths:\r\n",
        "  splits= val_path.split(\"/\")\r\n",
        "  filename = splits[-1]\r\n",
        "  label = splits[4]\r\n",
        "  new_filepath = os.path.join(validation_dir,label,filename)\r\n",
        "  if not os.path.isfile(new_filepath):\r\n",
        "    shutil.move(val_path,new_filepath)\r\n",
        "  print(\"moving file from\",val_path,\" to \",filepath)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "moving file from /content/VehicleDataset/train/qingqi/f99843280.jpg  to  ['', 'content', 'VehicleDataset', 'test', 'f58077242.jpg']\n",
            "moving file from /content/VehicleDataset/train/tanga/f36609940.jpg  to  ['', 'content', 'VehicleDataset', 'test', 'f58077242.jpg']\n",
            "moving file from /content/VehicleDataset/train/tanga/f33783265.jpg  to  ['', 'content', 'VehicleDataset', 'test', 'f58077242.jpg']\n",
            "moving file from /content/VehicleDataset/train/rickshaw/f47236198.jpg  to  ['', 'content', 'VehicleDataset', 'test', 'f58077242.jpg']\n",
            "moving file from /content/VehicleDataset/train/qingqi/f92467888.jpg  to  ['', 'content', 'VehicleDataset', 'test', 'f58077242.jpg']\n",
            "moving file from /content/VehicleDataset/train/rickshaw/f44247255.jpg  to  ['', 'content', 'VehicleDataset', 'test', 'f58077242.jpg']\n",
            "moving file from /content/VehicleDataset/train/rickshaw/f22561633.jpg  to  ['', 'content', 'VehicleDataset', 'test', 'f58077242.jpg']\n",
            "moving file from /content/VehicleDataset/train/qingqi/f51879937.jpg  to  ['', 'content', 'VehicleDataset', 'test', 'f58077242.jpg']\n",
            "moving file from /content/VehicleDataset/train/tanga/f30533007.jpg  to  ['', 'content', 'VehicleDataset', 'test', 'f58077242.jpg']\n",
            "moving file from /content/VehicleDataset/train/qingqi/f24957437.jpg  to  ['', 'content', 'VehicleDataset', 'test', 'f58077242.jpg']\n",
            "moving file from /content/VehicleDataset/train/rickshaw/f66050221.jpg  to  ['', 'content', 'VehicleDataset', 'test', 'f58077242.jpg']\n",
            "moving file from /content/VehicleDataset/train/rickshaw/f15660733.jpg  to  ['', 'content', 'VehicleDataset', 'test', 'f58077242.jpg']\n",
            "moving file from /content/VehicleDataset/train/qingqi/f60816131.jpg  to  ['', 'content', 'VehicleDataset', 'test', 'f58077242.jpg']\n",
            "moving file from /content/VehicleDataset/train/tanga/f25837826.jpg  to  ['', 'content', 'VehicleDataset', 'test', 'f58077242.jpg']\n",
            "moving file from /content/VehicleDataset/train/rickshaw/f37339902.jpg  to  ['', 'content', 'VehicleDataset', 'test', 'f58077242.jpg']\n",
            "moving file from /content/VehicleDataset/train/tanga/f55237371.jpg  to  ['', 'content', 'VehicleDataset', 'test', 'f58077242.jpg']\n",
            "moving file from /content/VehicleDataset/train/rickshaw/f75135697.jpg  to  ['', 'content', 'VehicleDataset', 'test', 'f58077242.jpg']\n",
            "moving file from /content/VehicleDataset/train/tanga/f62714799.jpg  to  ['', 'content', 'VehicleDataset', 'test', 'f58077242.jpg']\n",
            "moving file from /content/VehicleDataset/train/qingqi/f51482523.jpg  to  ['', 'content', 'VehicleDataset', 'test', 'f58077242.jpg']\n",
            "moving file from /content/VehicleDataset/train/rickshaw/f35337067.jpg  to  ['', 'content', 'VehicleDataset', 'test', 'f58077242.jpg']\n",
            "moving file from /content/VehicleDataset/train/qingqi/f13136777.jpg  to  ['', 'content', 'VehicleDataset', 'test', 'f58077242.jpg']\n",
            "moving file from /content/VehicleDataset/train/tanga/f57786933.jpg  to  ['', 'content', 'VehicleDataset', 'test', 'f58077242.jpg']\n",
            "moving file from /content/VehicleDataset/train/rickshaw/f40718220.jpg  to  ['', 'content', 'VehicleDataset', 'test', 'f58077242.jpg']\n",
            "moving file from /content/VehicleDataset/train/rickshaw/f62393978.jpg  to  ['', 'content', 'VehicleDataset', 'test', 'f58077242.jpg']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_zyN4XYE5i9-",
        "outputId": "ae565fb3-1bc7-4327-8452-8ffa60b4253f"
      },
      "source": [
        "train_dataset = image_dataset_from_directory(training_dir,\r\n",
        "                                            shuffle=True,\r\n",
        "                                            batch_size=batch_size,\r\n",
        "                                            image_size=input_shape,\r\n",
        "                                             label_mode = 'categorical')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 216 files belonging to 3 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zLc56pgO9lv8",
        "outputId": "bed5b50e-b4d0-4a7e-a11c-cdbcba832ca6"
      },
      "source": [
        "validation_dataset = image_dataset_from_directory(validation_dir,\r\n",
        "                                             shuffle=True,\r\n",
        "                                             batch_size=batch_size,\r\n",
        "                                             image_size=input_shape,\r\n",
        "                                             label_mode = 'categorical')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 24 files belonging to 3 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-V-hOicLzEC"
      },
      "source": [
        "### Feature Extraction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1w6b8mXLzEC"
      },
      "source": [
        "In this step, you will freeze the convolutional base created from the previous step and to use as a feature extractor. Additionally, you add a classifier on top of it and train the top-level classifier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2CXhvtAgCiEy"
      },
      "source": [
        "preprocess_input = tf.keras.applications.efficientnet.preprocess_input\r\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V9r3uzJ3LzED",
        "outputId": "39895cab-d477-4164-a165-11ad0a89e5e5"
      },
      "source": [
        "# intialize the base model here and print the model summary\r\n",
        "base_model = tf.keras.applications.EfficientNetB7(input_shape=input_shape +(3,),\r\n",
        "                                               include_top=False,\r\n",
        "                                               weights='imagenet')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb7_notop.h5\n",
            "258080768/258076736 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-XVs2fpjLzED"
      },
      "source": [
        "# Freeze the base Model\r\n",
        "base_model.trainable = False"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RniqGcG1LzEE"
      },
      "source": [
        "It is important to freeze the convolutional base before you compile and train the model. Freezing (by setting layer.trainable = False) prevents the weights in a given layer from being updated during training. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZ-gLJw0BOU7"
      },
      "source": [
        "data_augmentation = tf.keras.Sequential([\r\n",
        "  tf.keras.layers.experimental.preprocessing.RandomFlip('horizontal'),\r\n",
        "  tf.keras.layers.experimental.preprocessing.RandomRotation(0.2),\r\n",
        "])"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FB8Vmt1pC0TI"
      },
      "source": [
        "inputs = tf.keras.Input(shape=input_shape + (3,))\r\n",
        "x = data_augmentation(inputs)\r\n",
        "x = preprocess_input(x)\r\n",
        "x = base_model(x, training=False)\r\n",
        "x = tf.keras.layers.GlobalAveragePooling2D()(x)\r\n",
        "x = tf.keras.layers.Dropout(0.2)(x)\r\n",
        "outputs = tf.keras.layers.Dense(3,activation =\"softmax\")(x)\r\n",
        "model = tf.keras.Model(inputs, outputs)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26cwauPsLzEF",
        "outputId": "b1a99b8f-3a4b-4b7b-9561-782a86fd86d1"
      },
      "source": [
        "# compile the model and print the summary\r\n",
        "\r\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(lr=learning_rate),\r\n",
        "              loss=tf.keras.losses.CategoricalCrossentropy(),\r\n",
        "              metrics=['accuracy'])\r\n",
        "print(model.summary())"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 200, 200, 3)]     0         \n",
            "_________________________________________________________________\n",
            "sequential (Sequential)      (None, 200, 200, 3)       0         \n",
            "_________________________________________________________________\n",
            "efficientnetb7 (Functional)  (None, 7, 7, 2560)        64097687  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d (Gl (None, 2560)              0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 2560)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 3)                 7683      \n",
            "=================================================================\n",
            "Total params: 64,105,370\n",
            "Trainable params: 7,683\n",
            "Non-trainable params: 64,097,687\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QdSck7HrLzEG",
        "outputId": "d9eb4671-0140-42bd-b7dd-9b4be8207b7c"
      },
      "source": [
        "# fit the model\r\n",
        "model_path = os.path.join(os.getcwd(),\"model\")\r\n",
        "history = model.fit(train_dataset,epochs=epochs)\r\n",
        "model.save(model_path)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/400\n",
            "7/7 [==============================] - 51s 495ms/step - loss: 1.1634 - accuracy: 0.2979\n",
            "Epoch 2/400\n",
            "7/7 [==============================] - 2s 305ms/step - loss: 1.1564 - accuracy: 0.3044\n",
            "Epoch 3/400\n",
            "7/7 [==============================] - 2s 308ms/step - loss: 1.1707 - accuracy: 0.2768\n",
            "Epoch 4/400\n",
            "7/7 [==============================] - 2s 307ms/step - loss: 1.1629 - accuracy: 0.2963\n",
            "Epoch 5/400\n",
            "7/7 [==============================] - 2s 307ms/step - loss: 1.1489 - accuracy: 0.3021\n",
            "Epoch 6/400\n",
            "7/7 [==============================] - 2s 309ms/step - loss: 1.1488 - accuracy: 0.3194\n",
            "Epoch 7/400\n",
            "7/7 [==============================] - 2s 310ms/step - loss: 1.1520 - accuracy: 0.3479\n",
            "Epoch 8/400\n",
            "7/7 [==============================] - 2s 311ms/step - loss: 1.1724 - accuracy: 0.2646\n",
            "Epoch 9/400\n",
            "7/7 [==============================] - 3s 314ms/step - loss: 1.1294 - accuracy: 0.3357\n",
            "Epoch 10/400\n",
            "7/7 [==============================] - 3s 315ms/step - loss: 1.1733 - accuracy: 0.2885\n",
            "Epoch 11/400\n",
            "7/7 [==============================] - 3s 316ms/step - loss: 1.1304 - accuracy: 0.3313\n",
            "Epoch 12/400\n",
            "7/7 [==============================] - 3s 317ms/step - loss: 1.1553 - accuracy: 0.3162\n",
            "Epoch 13/400\n",
            "7/7 [==============================] - 3s 317ms/step - loss: 1.0965 - accuracy: 0.3864\n",
            "Epoch 14/400\n",
            "7/7 [==============================] - 3s 319ms/step - loss: 1.1091 - accuracy: 0.2807\n",
            "Epoch 15/400\n",
            "7/7 [==============================] - 3s 321ms/step - loss: 1.1192 - accuracy: 0.3394\n",
            "Epoch 16/400\n",
            "7/7 [==============================] - 3s 322ms/step - loss: 1.1041 - accuracy: 0.3609\n",
            "Epoch 17/400\n",
            "7/7 [==============================] - 3s 323ms/step - loss: 1.1275 - accuracy: 0.3400\n",
            "Epoch 18/400\n",
            "7/7 [==============================] - 3s 325ms/step - loss: 1.0949 - accuracy: 0.3793\n",
            "Epoch 19/400\n",
            "7/7 [==============================] - 3s 326ms/step - loss: 1.1034 - accuracy: 0.3869\n",
            "Epoch 20/400\n",
            "7/7 [==============================] - 3s 326ms/step - loss: 1.1370 - accuracy: 0.3286\n",
            "Epoch 21/400\n",
            "7/7 [==============================] - 3s 321ms/step - loss: 1.0879 - accuracy: 0.3993\n",
            "Epoch 22/400\n",
            "7/7 [==============================] - 3s 320ms/step - loss: 1.1218 - accuracy: 0.3215\n",
            "Epoch 23/400\n",
            "7/7 [==============================] - 3s 318ms/step - loss: 1.1354 - accuracy: 0.2971\n",
            "Epoch 24/400\n",
            "7/7 [==============================] - 3s 318ms/step - loss: 1.1164 - accuracy: 0.3200\n",
            "Epoch 25/400\n",
            "7/7 [==============================] - 3s 315ms/step - loss: 1.0589 - accuracy: 0.4152\n",
            "Epoch 26/400\n",
            "7/7 [==============================] - 2s 314ms/step - loss: 1.0755 - accuracy: 0.4490\n",
            "Epoch 27/400\n",
            "7/7 [==============================] - 2s 314ms/step - loss: 1.0860 - accuracy: 0.3688\n",
            "Epoch 28/400\n",
            "7/7 [==============================] - 3s 315ms/step - loss: 1.0607 - accuracy: 0.4275\n",
            "Epoch 29/400\n",
            "7/7 [==============================] - 2s 313ms/step - loss: 1.0744 - accuracy: 0.4124\n",
            "Epoch 30/400\n",
            "7/7 [==============================] - 2s 313ms/step - loss: 1.0609 - accuracy: 0.4446\n",
            "Epoch 31/400\n",
            "7/7 [==============================] - 2s 312ms/step - loss: 1.0618 - accuracy: 0.4512\n",
            "Epoch 32/400\n",
            "7/7 [==============================] - 2s 311ms/step - loss: 1.0283 - accuracy: 0.4799\n",
            "Epoch 33/400\n",
            "7/7 [==============================] - 3s 310ms/step - loss: 1.0521 - accuracy: 0.4494\n",
            "Epoch 34/400\n",
            "7/7 [==============================] - 3s 313ms/step - loss: 1.0477 - accuracy: 0.4596\n",
            "Epoch 35/400\n",
            "7/7 [==============================] - 2s 311ms/step - loss: 1.0542 - accuracy: 0.4669\n",
            "Epoch 36/400\n",
            "7/7 [==============================] - 2s 310ms/step - loss: 1.0413 - accuracy: 0.4563\n",
            "Epoch 37/400\n",
            "7/7 [==============================] - 2s 313ms/step - loss: 1.0463 - accuracy: 0.4417\n",
            "Epoch 38/400\n",
            "7/7 [==============================] - 2s 315ms/step - loss: 1.0277 - accuracy: 0.4707\n",
            "Epoch 39/400\n",
            "7/7 [==============================] - 2s 313ms/step - loss: 1.0098 - accuracy: 0.5198\n",
            "Epoch 40/400\n",
            "7/7 [==============================] - 2s 315ms/step - loss: 1.0478 - accuracy: 0.4194\n",
            "Epoch 41/400\n",
            "7/7 [==============================] - 2s 312ms/step - loss: 1.0266 - accuracy: 0.5352\n",
            "Epoch 42/400\n",
            "7/7 [==============================] - 3s 316ms/step - loss: 1.0336 - accuracy: 0.4030\n",
            "Epoch 43/400\n",
            "7/7 [==============================] - 3s 318ms/step - loss: 1.0281 - accuracy: 0.4257\n",
            "Epoch 44/400\n",
            "7/7 [==============================] - 3s 320ms/step - loss: 1.0178 - accuracy: 0.4662\n",
            "Epoch 45/400\n",
            "7/7 [==============================] - 3s 319ms/step - loss: 1.0137 - accuracy: 0.5217\n",
            "Epoch 46/400\n",
            "7/7 [==============================] - 3s 321ms/step - loss: 1.0516 - accuracy: 0.4530\n",
            "Epoch 47/400\n",
            "7/7 [==============================] - 3s 320ms/step - loss: 1.0258 - accuracy: 0.4809\n",
            "Epoch 48/400\n",
            "7/7 [==============================] - 3s 320ms/step - loss: 0.9831 - accuracy: 0.5575\n",
            "Epoch 49/400\n",
            "7/7 [==============================] - 3s 321ms/step - loss: 1.0168 - accuracy: 0.5633\n",
            "Epoch 50/400\n",
            "7/7 [==============================] - 3s 318ms/step - loss: 1.0037 - accuracy: 0.5488\n",
            "Epoch 51/400\n",
            "7/7 [==============================] - 3s 318ms/step - loss: 0.9938 - accuracy: 0.5256\n",
            "Epoch 52/400\n",
            "7/7 [==============================] - 3s 317ms/step - loss: 1.0222 - accuracy: 0.5338\n",
            "Epoch 53/400\n",
            "7/7 [==============================] - 3s 316ms/step - loss: 0.9999 - accuracy: 0.5410\n",
            "Epoch 54/400\n",
            "7/7 [==============================] - 3s 316ms/step - loss: 0.9995 - accuracy: 0.5634\n",
            "Epoch 55/400\n",
            "7/7 [==============================] - 3s 316ms/step - loss: 1.0127 - accuracy: 0.4950\n",
            "Epoch 56/400\n",
            "7/7 [==============================] - 3s 315ms/step - loss: 0.9826 - accuracy: 0.5377\n",
            "Epoch 57/400\n",
            "7/7 [==============================] - 3s 316ms/step - loss: 0.9938 - accuracy: 0.5001\n",
            "Epoch 58/400\n",
            "7/7 [==============================] - 3s 314ms/step - loss: 0.9765 - accuracy: 0.5823\n",
            "Epoch 59/400\n",
            "7/7 [==============================] - 3s 313ms/step - loss: 0.9639 - accuracy: 0.5736\n",
            "Epoch 60/400\n",
            "7/7 [==============================] - 2s 314ms/step - loss: 0.9768 - accuracy: 0.5239\n",
            "Epoch 61/400\n",
            "7/7 [==============================] - 3s 315ms/step - loss: 0.9781 - accuracy: 0.5626\n",
            "Epoch 62/400\n",
            "7/7 [==============================] - 2s 312ms/step - loss: 0.9460 - accuracy: 0.6010\n",
            "Epoch 63/400\n",
            "7/7 [==============================] - 3s 317ms/step - loss: 0.9783 - accuracy: 0.5408\n",
            "Epoch 64/400\n",
            "7/7 [==============================] - 2s 315ms/step - loss: 0.9562 - accuracy: 0.6169\n",
            "Epoch 65/400\n",
            "7/7 [==============================] - 2s 314ms/step - loss: 0.9901 - accuracy: 0.5842\n",
            "Epoch 66/400\n",
            "7/7 [==============================] - 3s 316ms/step - loss: 0.9555 - accuracy: 0.6265\n",
            "Epoch 67/400\n",
            "7/7 [==============================] - 2s 315ms/step - loss: 0.9852 - accuracy: 0.5435\n",
            "Epoch 68/400\n",
            "7/7 [==============================] - 3s 316ms/step - loss: 0.9392 - accuracy: 0.6490\n",
            "Epoch 69/400\n",
            "7/7 [==============================] - 2s 315ms/step - loss: 0.9418 - accuracy: 0.6149\n",
            "Epoch 70/400\n",
            "7/7 [==============================] - 3s 315ms/step - loss: 0.9431 - accuracy: 0.6199\n",
            "Epoch 71/400\n",
            "7/7 [==============================] - 3s 317ms/step - loss: 0.9481 - accuracy: 0.6510\n",
            "Epoch 72/400\n",
            "7/7 [==============================] - 3s 317ms/step - loss: 0.9414 - accuracy: 0.6122\n",
            "Epoch 73/400\n",
            "7/7 [==============================] - 3s 317ms/step - loss: 0.9527 - accuracy: 0.5974\n",
            "Epoch 74/400\n",
            "7/7 [==============================] - 3s 316ms/step - loss: 0.9086 - accuracy: 0.6714\n",
            "Epoch 75/400\n",
            "7/7 [==============================] - 3s 317ms/step - loss: 0.9593 - accuracy: 0.5176\n",
            "Epoch 76/400\n",
            "7/7 [==============================] - 3s 317ms/step - loss: 0.9214 - accuracy: 0.6311\n",
            "Epoch 77/400\n",
            "7/7 [==============================] - 3s 317ms/step - loss: 0.9375 - accuracy: 0.6206\n",
            "Epoch 78/400\n",
            "7/7 [==============================] - 3s 316ms/step - loss: 0.9175 - accuracy: 0.6331\n",
            "Epoch 79/400\n",
            "7/7 [==============================] - 3s 317ms/step - loss: 0.9379 - accuracy: 0.5950\n",
            "Epoch 80/400\n",
            "7/7 [==============================] - 2s 313ms/step - loss: 0.9028 - accuracy: 0.6931\n",
            "Epoch 81/400\n",
            "7/7 [==============================] - 3s 316ms/step - loss: 0.9145 - accuracy: 0.6482\n",
            "Epoch 82/400\n",
            "7/7 [==============================] - 3s 315ms/step - loss: 0.9192 - accuracy: 0.6955\n",
            "Epoch 83/400\n",
            "7/7 [==============================] - 3s 317ms/step - loss: 0.9006 - accuracy: 0.6568\n",
            "Epoch 84/400\n",
            "7/7 [==============================] - 3s 316ms/step - loss: 0.8965 - accuracy: 0.6917\n",
            "Epoch 85/400\n",
            "7/7 [==============================] - 3s 317ms/step - loss: 0.8990 - accuracy: 0.6943\n",
            "Epoch 86/400\n",
            "7/7 [==============================] - 3s 315ms/step - loss: 0.8971 - accuracy: 0.6370\n",
            "Epoch 87/400\n",
            "7/7 [==============================] - 2s 316ms/step - loss: 0.8953 - accuracy: 0.6263\n",
            "Epoch 88/400\n",
            "7/7 [==============================] - 3s 315ms/step - loss: 0.9119 - accuracy: 0.6295\n",
            "Epoch 89/400\n",
            "7/7 [==============================] - 2s 315ms/step - loss: 0.8848 - accuracy: 0.6825\n",
            "Epoch 90/400\n",
            "7/7 [==============================] - 3s 316ms/step - loss: 0.9342 - accuracy: 0.6204\n",
            "Epoch 91/400\n",
            "7/7 [==============================] - 2s 315ms/step - loss: 0.8892 - accuracy: 0.7113\n",
            "Epoch 92/400\n",
            "7/7 [==============================] - 3s 315ms/step - loss: 0.8700 - accuracy: 0.7289\n",
            "Epoch 93/400\n",
            "7/7 [==============================] - 3s 315ms/step - loss: 0.8879 - accuracy: 0.6744\n",
            "Epoch 94/400\n",
            "7/7 [==============================] - 2s 314ms/step - loss: 0.8689 - accuracy: 0.6784\n",
            "Epoch 95/400\n",
            "7/7 [==============================] - 3s 318ms/step - loss: 0.8808 - accuracy: 0.7168\n",
            "Epoch 96/400\n",
            "7/7 [==============================] - 3s 317ms/step - loss: 0.8734 - accuracy: 0.7167\n",
            "Epoch 97/400\n",
            "7/7 [==============================] - 3s 319ms/step - loss: 0.8805 - accuracy: 0.7187\n",
            "Epoch 98/400\n",
            "7/7 [==============================] - 3s 317ms/step - loss: 0.9002 - accuracy: 0.6456\n",
            "Epoch 99/400\n",
            "7/7 [==============================] - 3s 317ms/step - loss: 0.8667 - accuracy: 0.7516\n",
            "Epoch 100/400\n",
            "7/7 [==============================] - 3s 316ms/step - loss: 0.8292 - accuracy: 0.7881\n",
            "Epoch 101/400\n",
            "7/7 [==============================] - 3s 317ms/step - loss: 0.8708 - accuracy: 0.6907\n",
            "Epoch 102/400\n",
            "7/7 [==============================] - 3s 318ms/step - loss: 0.8462 - accuracy: 0.7016\n",
            "Epoch 103/400\n",
            "7/7 [==============================] - 3s 317ms/step - loss: 0.8428 - accuracy: 0.7280\n",
            "Epoch 104/400\n",
            "7/7 [==============================] - 3s 318ms/step - loss: 0.9016 - accuracy: 0.6206\n",
            "Epoch 105/400\n",
            "7/7 [==============================] - 3s 318ms/step - loss: 0.8358 - accuracy: 0.7609\n",
            "Epoch 106/400\n",
            "7/7 [==============================] - 3s 315ms/step - loss: 0.8592 - accuracy: 0.7059\n",
            "Epoch 107/400\n",
            "7/7 [==============================] - 3s 316ms/step - loss: 0.8376 - accuracy: 0.7730\n",
            "Epoch 108/400\n",
            "7/7 [==============================] - 3s 317ms/step - loss: 0.8057 - accuracy: 0.8179\n",
            "Epoch 109/400\n",
            "7/7 [==============================] - 2s 316ms/step - loss: 0.8321 - accuracy: 0.7400\n",
            "Epoch 110/400\n",
            "7/7 [==============================] - 3s 316ms/step - loss: 0.8366 - accuracy: 0.7984\n",
            "Epoch 111/400\n",
            "7/7 [==============================] - 2s 315ms/step - loss: 0.8283 - accuracy: 0.7914\n",
            "Epoch 112/400\n",
            "7/7 [==============================] - 3s 315ms/step - loss: 0.8411 - accuracy: 0.7472\n",
            "Epoch 113/400\n",
            "7/7 [==============================] - 2s 315ms/step - loss: 0.8387 - accuracy: 0.7341\n",
            "Epoch 114/400\n",
            "7/7 [==============================] - 3s 316ms/step - loss: 0.8114 - accuracy: 0.7427\n",
            "Epoch 115/400\n",
            "7/7 [==============================] - 2s 315ms/step - loss: 0.8211 - accuracy: 0.7213\n",
            "Epoch 116/400\n",
            "7/7 [==============================] - 3s 317ms/step - loss: 0.8398 - accuracy: 0.7052\n",
            "Epoch 117/400\n",
            "7/7 [==============================] - 3s 317ms/step - loss: 0.8469 - accuracy: 0.7069\n",
            "Epoch 118/400\n",
            "7/7 [==============================] - 3s 316ms/step - loss: 0.8345 - accuracy: 0.7493\n",
            "Epoch 119/400\n",
            "7/7 [==============================] - 3s 316ms/step - loss: 0.8154 - accuracy: 0.7440\n",
            "Epoch 120/400\n",
            "7/7 [==============================] - 3s 317ms/step - loss: 0.7997 - accuracy: 0.7703\n",
            "Epoch 121/400\n",
            "7/7 [==============================] - 3s 316ms/step - loss: 0.8158 - accuracy: 0.7790\n",
            "Epoch 122/400\n",
            "7/7 [==============================] - 3s 316ms/step - loss: 0.8161 - accuracy: 0.7594\n",
            "Epoch 123/400\n",
            "7/7 [==============================] - 3s 316ms/step - loss: 0.8356 - accuracy: 0.7466\n",
            "Epoch 124/400\n",
            "7/7 [==============================] - 3s 316ms/step - loss: 0.8107 - accuracy: 0.8052\n",
            "Epoch 125/400\n",
            "7/7 [==============================] - 3s 317ms/step - loss: 0.8281 - accuracy: 0.7641\n",
            "Epoch 126/400\n",
            "7/7 [==============================] - 3s 315ms/step - loss: 0.7985 - accuracy: 0.7982\n",
            "Epoch 127/400\n",
            "7/7 [==============================] - 3s 316ms/step - loss: 0.8125 - accuracy: 0.7569\n",
            "Epoch 128/400\n",
            "7/7 [==============================] - 3s 318ms/step - loss: 0.8165 - accuracy: 0.7755\n",
            "Epoch 129/400\n",
            "7/7 [==============================] - 3s 316ms/step - loss: 0.7966 - accuracy: 0.7643\n",
            "Epoch 130/400\n",
            "7/7 [==============================] - 3s 316ms/step - loss: 0.7839 - accuracy: 0.7347\n",
            "Epoch 131/400\n",
            "7/7 [==============================] - 3s 316ms/step - loss: 0.8227 - accuracy: 0.7134\n",
            "Epoch 132/400\n",
            "7/7 [==============================] - 3s 316ms/step - loss: 0.7747 - accuracy: 0.7940\n",
            "Epoch 133/400\n",
            "7/7 [==============================] - 3s 316ms/step - loss: 0.7879 - accuracy: 0.8058\n",
            "Epoch 134/400\n",
            "7/7 [==============================] - 3s 316ms/step - loss: 0.8062 - accuracy: 0.7550\n",
            "Epoch 135/400\n",
            "7/7 [==============================] - 3s 315ms/step - loss: 0.8015 - accuracy: 0.7498\n",
            "Epoch 136/400\n",
            "7/7 [==============================] - 3s 316ms/step - loss: 0.7949 - accuracy: 0.8174\n",
            "Epoch 137/400\n",
            "7/7 [==============================] - 3s 316ms/step - loss: 0.7826 - accuracy: 0.7507\n",
            "Epoch 138/400\n",
            "7/7 [==============================] - 3s 316ms/step - loss: 0.7944 - accuracy: 0.7179\n",
            "Epoch 139/400\n",
            "7/7 [==============================] - 3s 316ms/step - loss: 0.7572 - accuracy: 0.8241\n",
            "Epoch 140/400\n",
            "7/7 [==============================] - 3s 317ms/step - loss: 0.7598 - accuracy: 0.7727\n",
            "Epoch 141/400\n",
            "7/7 [==============================] - 3s 319ms/step - loss: 0.7719 - accuracy: 0.7943\n",
            "Epoch 142/400\n",
            "7/7 [==============================] - 3s 317ms/step - loss: 0.7739 - accuracy: 0.7862\n",
            "Epoch 143/400\n",
            "7/7 [==============================] - 3s 317ms/step - loss: 0.7883 - accuracy: 0.7885\n",
            "Epoch 144/400\n",
            "7/7 [==============================] - 3s 317ms/step - loss: 0.7748 - accuracy: 0.7410\n",
            "Epoch 145/400\n",
            "7/7 [==============================] - 3s 316ms/step - loss: 0.7689 - accuracy: 0.8155\n",
            "Epoch 146/400\n",
            "7/7 [==============================] - 3s 318ms/step - loss: 0.7732 - accuracy: 0.7760\n",
            "Epoch 147/400\n",
            "7/7 [==============================] - 3s 318ms/step - loss: 0.7733 - accuracy: 0.7534\n",
            "Epoch 148/400\n",
            "7/7 [==============================] - 3s 316ms/step - loss: 0.7543 - accuracy: 0.7730\n",
            "Epoch 149/400\n",
            "7/7 [==============================] - 3s 315ms/step - loss: 0.7656 - accuracy: 0.8165\n",
            "Epoch 150/400\n",
            "7/7 [==============================] - 3s 317ms/step - loss: 0.7890 - accuracy: 0.7704\n",
            "Epoch 151/400\n",
            "7/7 [==============================] - 3s 317ms/step - loss: 0.7476 - accuracy: 0.7854\n",
            "Epoch 152/400\n",
            "7/7 [==============================] - 3s 316ms/step - loss: 0.7447 - accuracy: 0.7987\n",
            "Epoch 153/400\n",
            "7/7 [==============================] - 3s 316ms/step - loss: 0.7742 - accuracy: 0.7482\n",
            "Epoch 154/400\n",
            "7/7 [==============================] - 3s 317ms/step - loss: 0.7611 - accuracy: 0.7734\n",
            "Epoch 155/400\n",
            "7/7 [==============================] - 2s 315ms/step - loss: 0.7212 - accuracy: 0.8197\n",
            "Epoch 156/400\n",
            "7/7 [==============================] - 3s 317ms/step - loss: 0.7346 - accuracy: 0.8357\n",
            "Epoch 157/400\n",
            "7/7 [==============================] - 2s 314ms/step - loss: 0.7450 - accuracy: 0.8112\n",
            "Epoch 158/400\n",
            "7/7 [==============================] - 3s 316ms/step - loss: 0.7216 - accuracy: 0.8230\n",
            "Epoch 159/400\n",
            "7/7 [==============================] - 2s 316ms/step - loss: 0.7339 - accuracy: 0.8220\n",
            "Epoch 160/400\n",
            "7/7 [==============================] - 3s 317ms/step - loss: 0.7618 - accuracy: 0.7311\n",
            "Epoch 161/400\n",
            "7/7 [==============================] - 3s 316ms/step - loss: 0.7566 - accuracy: 0.7915\n",
            "Epoch 162/400\n",
            "7/7 [==============================] - 3s 317ms/step - loss: 0.7340 - accuracy: 0.7823\n",
            "Epoch 163/400\n",
            "7/7 [==============================] - 3s 316ms/step - loss: 0.7406 - accuracy: 0.7944\n",
            "Epoch 164/400\n",
            "7/7 [==============================] - 3s 316ms/step - loss: 0.7311 - accuracy: 0.7774\n",
            "Epoch 165/400\n",
            "7/7 [==============================] - 3s 316ms/step - loss: 0.7302 - accuracy: 0.8262\n",
            "Epoch 166/400\n",
            "7/7 [==============================] - 2s 315ms/step - loss: 0.7479 - accuracy: 0.7892\n",
            "Epoch 167/400\n",
            "7/7 [==============================] - 3s 316ms/step - loss: 0.7694 - accuracy: 0.7624\n",
            "Epoch 168/400\n",
            "7/7 [==============================] - 2s 315ms/step - loss: 0.7360 - accuracy: 0.8197\n",
            "Epoch 169/400\n",
            "7/7 [==============================] - 3s 316ms/step - loss: 0.7367 - accuracy: 0.7807\n",
            "Epoch 170/400\n",
            "7/7 [==============================] - 3s 316ms/step - loss: 0.7648 - accuracy: 0.7926\n",
            "Epoch 171/400\n",
            "7/7 [==============================] - 3s 316ms/step - loss: 0.7419 - accuracy: 0.7963\n",
            "Epoch 172/400\n",
            "7/7 [==============================] - 3s 316ms/step - loss: 0.7148 - accuracy: 0.8474\n",
            "Epoch 173/400\n",
            "7/7 [==============================] - 3s 316ms/step - loss: 0.7295 - accuracy: 0.7818\n",
            "Epoch 174/400\n",
            "7/7 [==============================] - 3s 317ms/step - loss: 0.7036 - accuracy: 0.8186\n",
            "Epoch 175/400\n",
            "7/7 [==============================] - 3s 317ms/step - loss: 0.7236 - accuracy: 0.8407\n",
            "Epoch 176/400\n",
            "7/7 [==============================] - 2s 316ms/step - loss: 0.7524 - accuracy: 0.7733\n",
            "Epoch 177/400\n",
            "7/7 [==============================] - 3s 317ms/step - loss: 0.7129 - accuracy: 0.8244\n",
            "Epoch 178/400\n",
            "7/7 [==============================] - 3s 316ms/step - loss: 0.7002 - accuracy: 0.8159\n",
            "Epoch 179/400\n",
            "7/7 [==============================] - 3s 316ms/step - loss: 0.7133 - accuracy: 0.8220\n",
            "Epoch 180/400\n",
            "7/7 [==============================] - 3s 317ms/step - loss: 0.7020 - accuracy: 0.8373\n",
            "Epoch 181/400\n",
            "7/7 [==============================] - 2s 316ms/step - loss: 0.7120 - accuracy: 0.8207\n",
            "Epoch 182/400\n",
            "7/7 [==============================] - 3s 319ms/step - loss: 0.7239 - accuracy: 0.7962\n",
            "Epoch 183/400\n",
            "7/7 [==============================] - 3s 317ms/step - loss: 0.7119 - accuracy: 0.8254\n",
            "Epoch 184/400\n",
            "7/7 [==============================] - 3s 316ms/step - loss: 0.6974 - accuracy: 0.8272\n",
            "Epoch 185/400\n",
            "7/7 [==============================] - 3s 317ms/step - loss: 0.6994 - accuracy: 0.8254\n",
            "Epoch 186/400\n",
            "7/7 [==============================] - 3s 316ms/step - loss: 0.7016 - accuracy: 0.7973\n",
            "Epoch 187/400\n",
            "7/7 [==============================] - 3s 316ms/step - loss: 0.6952 - accuracy: 0.8317\n",
            "Epoch 188/400\n",
            "7/7 [==============================] - 3s 314ms/step - loss: 0.7268 - accuracy: 0.7613\n",
            "Epoch 189/400\n",
            "7/7 [==============================] - 3s 318ms/step - loss: 0.6898 - accuracy: 0.8310\n",
            "Epoch 190/400\n",
            "7/7 [==============================] - 3s 316ms/step - loss: 0.6655 - accuracy: 0.8538\n",
            "Epoch 191/400\n",
            "7/7 [==============================] - 3s 316ms/step - loss: 0.7059 - accuracy: 0.8237\n",
            "Epoch 192/400\n",
            "7/7 [==============================] - 3s 316ms/step - loss: 0.6582 - accuracy: 0.8667\n",
            "Epoch 193/400\n",
            "7/7 [==============================] - 3s 318ms/step - loss: 0.6853 - accuracy: 0.8282\n",
            "Epoch 194/400\n",
            "7/7 [==============================] - 3s 316ms/step - loss: 0.6835 - accuracy: 0.8574\n",
            "Epoch 195/400\n",
            "7/7 [==============================] - 3s 318ms/step - loss: 0.6994 - accuracy: 0.8280\n",
            "Epoch 196/400\n",
            "7/7 [==============================] - 3s 317ms/step - loss: 0.6898 - accuracy: 0.8196\n",
            "Epoch 197/400\n",
            "7/7 [==============================] - 3s 319ms/step - loss: 0.6620 - accuracy: 0.8375\n",
            "Epoch 198/400\n",
            "7/7 [==============================] - 3s 316ms/step - loss: 0.6567 - accuracy: 0.8479\n",
            "Epoch 199/400\n",
            "7/7 [==============================] - 2s 315ms/step - loss: 0.6550 - accuracy: 0.8247\n",
            "Epoch 200/400\n",
            "7/7 [==============================] - 3s 317ms/step - loss: 0.6710 - accuracy: 0.8529\n",
            "Epoch 201/400\n",
            "7/7 [==============================] - 2s 314ms/step - loss: 0.6907 - accuracy: 0.8114\n",
            "Epoch 202/400\n",
            "7/7 [==============================] - 3s 317ms/step - loss: 0.6789 - accuracy: 0.8406\n",
            "Epoch 203/400\n",
            "7/7 [==============================] - 3s 318ms/step - loss: 0.6664 - accuracy: 0.8473\n",
            "Epoch 204/400\n",
            "7/7 [==============================] - 3s 318ms/step - loss: 0.6617 - accuracy: 0.8331\n",
            "Epoch 205/400\n",
            "7/7 [==============================] - 3s 317ms/step - loss: 0.6896 - accuracy: 0.8303\n",
            "Epoch 206/400\n",
            "7/7 [==============================] - 3s 317ms/step - loss: 0.6563 - accuracy: 0.8734\n",
            "Epoch 207/400\n",
            "7/7 [==============================] - 3s 316ms/step - loss: 0.6692 - accuracy: 0.8186\n",
            "Epoch 208/400\n",
            "7/7 [==============================] - 3s 316ms/step - loss: 0.6725 - accuracy: 0.8308\n",
            "Epoch 209/400\n",
            "7/7 [==============================] - 3s 316ms/step - loss: 0.6829 - accuracy: 0.8042\n",
            "Epoch 210/400\n",
            "7/7 [==============================] - 3s 315ms/step - loss: 0.6913 - accuracy: 0.8109\n",
            "Epoch 211/400\n",
            "7/7 [==============================] - 3s 315ms/step - loss: 0.6977 - accuracy: 0.7582\n",
            "Epoch 212/400\n",
            "7/7 [==============================] - 3s 316ms/step - loss: 0.6355 - accuracy: 0.8116\n",
            "Epoch 213/400\n",
            "7/7 [==============================] - 3s 314ms/step - loss: 0.6702 - accuracy: 0.8168\n",
            "Epoch 214/400\n",
            "7/7 [==============================] - 2s 314ms/step - loss: 0.6641 - accuracy: 0.8504\n",
            "Epoch 215/400\n",
            "7/7 [==============================] - 3s 316ms/step - loss: 0.6202 - accuracy: 0.8730\n",
            "Epoch 216/400\n",
            "7/7 [==============================] - 3s 315ms/step - loss: 0.6473 - accuracy: 0.8088\n",
            "Epoch 217/400\n",
            "7/7 [==============================] - 3s 316ms/step - loss: 0.6389 - accuracy: 0.8750\n",
            "Epoch 218/400\n",
            "7/7 [==============================] - 3s 317ms/step - loss: 0.6284 - accuracy: 0.8663\n",
            "Epoch 219/400\n",
            "7/7 [==============================] - 3s 317ms/step - loss: 0.6200 - accuracy: 0.8801\n",
            "Epoch 220/400\n",
            "7/7 [==============================] - 3s 317ms/step - loss: 0.6328 - accuracy: 0.8476\n",
            "Epoch 221/400\n",
            "7/7 [==============================] - 2s 315ms/step - loss: 0.6199 - accuracy: 0.8705\n",
            "Epoch 222/400\n",
            "7/7 [==============================] - 3s 316ms/step - loss: 0.6550 - accuracy: 0.8280\n",
            "Epoch 223/400\n",
            "7/7 [==============================] - 3s 316ms/step - loss: 0.6737 - accuracy: 0.8229\n",
            "Epoch 224/400\n",
            "7/7 [==============================] - 3s 316ms/step - loss: 0.6432 - accuracy: 0.8465\n",
            "Epoch 225/400\n",
            "7/7 [==============================] - 3s 317ms/step - loss: 0.6390 - accuracy: 0.8117\n",
            "Epoch 226/400\n",
            "7/7 [==============================] - 3s 316ms/step - loss: 0.6086 - accuracy: 0.9107\n",
            "Epoch 227/400\n",
            "7/7 [==============================] - 3s 316ms/step - loss: 0.6414 - accuracy: 0.8308\n",
            "Epoch 228/400\n",
            "7/7 [==============================] - 3s 316ms/step - loss: 0.6181 - accuracy: 0.8599\n",
            "Epoch 229/400\n",
            "7/7 [==============================] - 3s 318ms/step - loss: 0.6442 - accuracy: 0.8261\n",
            "Epoch 230/400\n",
            "7/7 [==============================] - 3s 316ms/step - loss: 0.6358 - accuracy: 0.8572\n",
            "Epoch 231/400\n",
            "7/7 [==============================] - 2s 317ms/step - loss: 0.6353 - accuracy: 0.8349\n",
            "Epoch 232/400\n",
            "7/7 [==============================] - 3s 318ms/step - loss: 0.6752 - accuracy: 0.8049\n",
            "Epoch 233/400\n",
            "7/7 [==============================] - 3s 317ms/step - loss: 0.6174 - accuracy: 0.8554\n",
            "Epoch 234/400\n",
            "7/7 [==============================] - 3s 315ms/step - loss: 0.6379 - accuracy: 0.8136\n",
            "Epoch 235/400\n",
            "7/7 [==============================] - 3s 317ms/step - loss: 0.6184 - accuracy: 0.8921\n",
            "Epoch 236/400\n",
            "7/7 [==============================] - 3s 317ms/step - loss: 0.6464 - accuracy: 0.8173\n",
            "Epoch 237/400\n",
            "7/7 [==============================] - 2s 316ms/step - loss: 0.6409 - accuracy: 0.8334\n",
            "Epoch 238/400\n",
            "7/7 [==============================] - 3s 316ms/step - loss: 0.6094 - accuracy: 0.8649\n",
            "Epoch 239/400\n",
            "7/7 [==============================] - 2s 315ms/step - loss: 0.6353 - accuracy: 0.8004\n",
            "Epoch 240/400\n",
            "7/7 [==============================] - 3s 316ms/step - loss: 0.6408 - accuracy: 0.8072\n",
            "Epoch 241/400\n",
            "7/7 [==============================] - 3s 317ms/step - loss: 0.5907 - accuracy: 0.9074\n",
            "Epoch 242/400\n",
            "7/7 [==============================] - 3s 317ms/step - loss: 0.6421 - accuracy: 0.8429\n",
            "Epoch 243/400\n",
            "7/7 [==============================] - 3s 317ms/step - loss: 0.6290 - accuracy: 0.8507\n",
            "Epoch 244/400\n",
            "7/7 [==============================] - 3s 316ms/step - loss: 0.6134 - accuracy: 0.8375\n",
            "Epoch 245/400\n",
            "7/7 [==============================] - 3s 316ms/step - loss: 0.6328 - accuracy: 0.8321\n",
            "Epoch 246/400\n",
            "7/7 [==============================] - 3s 317ms/step - loss: 0.6052 - accuracy: 0.8748\n",
            "Epoch 247/400\n",
            "7/7 [==============================] - 3s 318ms/step - loss: 0.6295 - accuracy: 0.8545\n",
            "Epoch 248/400\n",
            "7/7 [==============================] - 3s 318ms/step - loss: 0.6231 - accuracy: 0.8659\n",
            "Epoch 249/400\n",
            "7/7 [==============================] - 3s 316ms/step - loss: 0.5820 - accuracy: 0.8829\n",
            "Epoch 250/400\n",
            "7/7 [==============================] - 3s 315ms/step - loss: 0.6019 - accuracy: 0.8629\n",
            "Epoch 251/400\n",
            "7/7 [==============================] - 3s 316ms/step - loss: 0.6362 - accuracy: 0.8635\n",
            "Epoch 252/400\n",
            "7/7 [==============================] - 3s 318ms/step - loss: 0.6363 - accuracy: 0.7982\n",
            "Epoch 253/400\n",
            "7/7 [==============================] - 3s 317ms/step - loss: 0.6360 - accuracy: 0.8008\n",
            "Epoch 254/400\n",
            "7/7 [==============================] - 3s 317ms/step - loss: 0.6092 - accuracy: 0.8620\n",
            "Epoch 255/400\n",
            "7/7 [==============================] - 3s 316ms/step - loss: 0.6106 - accuracy: 0.8493\n",
            "Epoch 256/400\n",
            "7/7 [==============================] - 3s 316ms/step - loss: 0.6018 - accuracy: 0.8796\n",
            "Epoch 257/400\n",
            "7/7 [==============================] - 3s 317ms/step - loss: 0.6145 - accuracy: 0.8278\n",
            "Epoch 258/400\n",
            "7/7 [==============================] - 3s 317ms/step - loss: 0.5816 - accuracy: 0.8686\n",
            "Epoch 259/400\n",
            "7/7 [==============================] - 3s 317ms/step - loss: 0.6301 - accuracy: 0.8441\n",
            "Epoch 260/400\n",
            "7/7 [==============================] - 3s 318ms/step - loss: 0.5752 - accuracy: 0.9063\n",
            "Epoch 261/400\n",
            "7/7 [==============================] - 3s 316ms/step - loss: 0.6168 - accuracy: 0.8312\n",
            "Epoch 262/400\n",
            "7/7 [==============================] - 3s 318ms/step - loss: 0.6244 - accuracy: 0.8367\n",
            "Epoch 263/400\n",
            "7/7 [==============================] - 3s 317ms/step - loss: 0.5979 - accuracy: 0.8528\n",
            "Epoch 264/400\n",
            "7/7 [==============================] - 3s 317ms/step - loss: 0.5852 - accuracy: 0.8747\n",
            "Epoch 265/400\n",
            "7/7 [==============================] - 3s 318ms/step - loss: 0.5578 - accuracy: 0.8811\n",
            "Epoch 266/400\n",
            "7/7 [==============================] - 3s 318ms/step - loss: 0.6088 - accuracy: 0.8586\n",
            "Epoch 267/400\n",
            "7/7 [==============================] - 3s 317ms/step - loss: 0.5735 - accuracy: 0.8817\n",
            "Epoch 268/400\n",
            "7/7 [==============================] - 3s 317ms/step - loss: 0.5532 - accuracy: 0.8976\n",
            "Epoch 269/400\n",
            "7/7 [==============================] - 3s 314ms/step - loss: 0.6016 - accuracy: 0.8430\n",
            "Epoch 270/400\n",
            "7/7 [==============================] - 3s 316ms/step - loss: 0.5903 - accuracy: 0.8347\n",
            "Epoch 271/400\n",
            "7/7 [==============================] - 3s 317ms/step - loss: 0.5923 - accuracy: 0.8567\n",
            "Epoch 272/400\n",
            "7/7 [==============================] - 3s 318ms/step - loss: 0.5927 - accuracy: 0.8997\n",
            "Epoch 273/400\n",
            "7/7 [==============================] - 3s 317ms/step - loss: 0.6147 - accuracy: 0.8444\n",
            "Epoch 274/400\n",
            "7/7 [==============================] - 3s 318ms/step - loss: 0.5883 - accuracy: 0.8588\n",
            "Epoch 275/400\n",
            "7/7 [==============================] - 3s 317ms/step - loss: 0.5998 - accuracy: 0.8153\n",
            "Epoch 276/400\n",
            "7/7 [==============================] - 2s 315ms/step - loss: 0.5847 - accuracy: 0.8626\n",
            "Epoch 277/400\n",
            "7/7 [==============================] - 2s 316ms/step - loss: 0.5621 - accuracy: 0.8637\n",
            "Epoch 278/400\n",
            "7/7 [==============================] - 2s 316ms/step - loss: 0.5749 - accuracy: 0.8637\n",
            "Epoch 279/400\n",
            "7/7 [==============================] - 2s 314ms/step - loss: 0.5982 - accuracy: 0.8383\n",
            "Epoch 280/400\n",
            "7/7 [==============================] - 3s 317ms/step - loss: 0.5631 - accuracy: 0.8572\n",
            "Epoch 281/400\n",
            "7/7 [==============================] - 3s 317ms/step - loss: 0.5855 - accuracy: 0.8588\n",
            "Epoch 282/400\n",
            "7/7 [==============================] - 3s 317ms/step - loss: 0.5825 - accuracy: 0.8365\n",
            "Epoch 283/400\n",
            "7/7 [==============================] - 3s 317ms/step - loss: 0.5818 - accuracy: 0.8491\n",
            "Epoch 284/400\n",
            "7/7 [==============================] - 3s 317ms/step - loss: 0.6037 - accuracy: 0.8453\n",
            "Epoch 285/400\n",
            "7/7 [==============================] - 3s 316ms/step - loss: 0.5682 - accuracy: 0.8707\n",
            "Epoch 286/400\n",
            "7/7 [==============================] - 3s 315ms/step - loss: 0.5511 - accuracy: 0.8810\n",
            "Epoch 287/400\n",
            "7/7 [==============================] - 2s 316ms/step - loss: 0.6064 - accuracy: 0.8362\n",
            "Epoch 288/400\n",
            "7/7 [==============================] - 3s 317ms/step - loss: 0.5830 - accuracy: 0.8136\n",
            "Epoch 289/400\n",
            "7/7 [==============================] - 2s 315ms/step - loss: 0.5645 - accuracy: 0.8333\n",
            "Epoch 290/400\n",
            "7/7 [==============================] - 2s 315ms/step - loss: 0.5392 - accuracy: 0.8999\n",
            "Epoch 291/400\n",
            "7/7 [==============================] - 2s 315ms/step - loss: 0.5798 - accuracy: 0.8497\n",
            "Epoch 292/400\n",
            "7/7 [==============================] - 2s 315ms/step - loss: 0.5722 - accuracy: 0.8358\n",
            "Epoch 293/400\n",
            "7/7 [==============================] - 3s 316ms/step - loss: 0.5620 - accuracy: 0.8571\n",
            "Epoch 294/400\n",
            "7/7 [==============================] - 3s 313ms/step - loss: 0.5407 - accuracy: 0.8669\n",
            "Epoch 295/400\n",
            "7/7 [==============================] - 3s 315ms/step - loss: 0.5645 - accuracy: 0.8812\n",
            "Epoch 296/400\n",
            "7/7 [==============================] - 3s 316ms/step - loss: 0.5655 - accuracy: 0.8862\n",
            "Epoch 297/400\n",
            "7/7 [==============================] - 3s 318ms/step - loss: 0.5757 - accuracy: 0.8260\n",
            "Epoch 298/400\n",
            "7/7 [==============================] - 3s 316ms/step - loss: 0.5643 - accuracy: 0.8566\n",
            "Epoch 299/400\n",
            "7/7 [==============================] - 3s 318ms/step - loss: 0.5472 - accuracy: 0.8853\n",
            "Epoch 300/400\n",
            "7/7 [==============================] - 3s 316ms/step - loss: 0.5689 - accuracy: 0.8353\n",
            "Epoch 301/400\n",
            "7/7 [==============================] - 3s 319ms/step - loss: 0.5594 - accuracy: 0.8738\n",
            "Epoch 302/400\n",
            "7/7 [==============================] - 2s 316ms/step - loss: 0.5631 - accuracy: 0.8930\n",
            "Epoch 303/400\n",
            "7/7 [==============================] - 3s 320ms/step - loss: 0.5484 - accuracy: 0.8776\n",
            "Epoch 304/400\n",
            "7/7 [==============================] - 3s 317ms/step - loss: 0.5646 - accuracy: 0.8722\n",
            "Epoch 305/400\n",
            "7/7 [==============================] - 3s 319ms/step - loss: 0.5411 - accuracy: 0.8865\n",
            "Epoch 306/400\n",
            "7/7 [==============================] - 3s 318ms/step - loss: 0.5087 - accuracy: 0.8795\n",
            "Epoch 307/400\n",
            "7/7 [==============================] - 3s 318ms/step - loss: 0.5549 - accuracy: 0.8313\n",
            "Epoch 308/400\n",
            "7/7 [==============================] - 3s 317ms/step - loss: 0.5584 - accuracy: 0.8410\n",
            "Epoch 309/400\n",
            "7/7 [==============================] - 3s 317ms/step - loss: 0.6135 - accuracy: 0.8489\n",
            "Epoch 310/400\n",
            "7/7 [==============================] - 2s 316ms/step - loss: 0.5086 - accuracy: 0.9206\n",
            "Epoch 311/400\n",
            "7/7 [==============================] - 3s 319ms/step - loss: 0.5713 - accuracy: 0.8570\n",
            "Epoch 312/400\n",
            "7/7 [==============================] - 3s 318ms/step - loss: 0.5224 - accuracy: 0.9130\n",
            "Epoch 313/400\n",
            "7/7 [==============================] - 3s 317ms/step - loss: 0.5215 - accuracy: 0.9179\n",
            "Epoch 314/400\n",
            "7/7 [==============================] - 3s 317ms/step - loss: 0.5272 - accuracy: 0.9078\n",
            "Epoch 315/400\n",
            "7/7 [==============================] - 3s 318ms/step - loss: 0.5438 - accuracy: 0.8861\n",
            "Epoch 316/400\n",
            "7/7 [==============================] - 3s 316ms/step - loss: 0.5478 - accuracy: 0.8793\n",
            "Epoch 317/400\n",
            "7/7 [==============================] - 3s 317ms/step - loss: 0.5042 - accuracy: 0.9334\n",
            "Epoch 318/400\n",
            "7/7 [==============================] - 3s 317ms/step - loss: 0.5347 - accuracy: 0.8908\n",
            "Epoch 319/400\n",
            "7/7 [==============================] - 3s 317ms/step - loss: 0.5020 - accuracy: 0.8895\n",
            "Epoch 320/400\n",
            "7/7 [==============================] - 2s 315ms/step - loss: 0.5391 - accuracy: 0.8748\n",
            "Epoch 321/400\n",
            "7/7 [==============================] - 3s 317ms/step - loss: 0.5580 - accuracy: 0.8738\n",
            "Epoch 322/400\n",
            "7/7 [==============================] - 3s 317ms/step - loss: 0.5585 - accuracy: 0.8432\n",
            "Epoch 323/400\n",
            "7/7 [==============================] - 3s 315ms/step - loss: 0.5271 - accuracy: 0.8944\n",
            "Epoch 324/400\n",
            "7/7 [==============================] - 3s 318ms/step - loss: 0.5379 - accuracy: 0.8797\n",
            "Epoch 325/400\n",
            "7/7 [==============================] - 3s 318ms/step - loss: 0.5041 - accuracy: 0.8997\n",
            "Epoch 326/400\n",
            "7/7 [==============================] - 3s 318ms/step - loss: 0.5132 - accuracy: 0.8971\n",
            "Epoch 327/400\n",
            "7/7 [==============================] - 3s 316ms/step - loss: 0.5394 - accuracy: 0.8846\n",
            "Epoch 328/400\n",
            "7/7 [==============================] - 3s 318ms/step - loss: 0.5123 - accuracy: 0.8849\n",
            "Epoch 329/400\n",
            "7/7 [==============================] - 3s 318ms/step - loss: 0.5214 - accuracy: 0.8782\n",
            "Epoch 330/400\n",
            "7/7 [==============================] - 3s 318ms/step - loss: 0.5347 - accuracy: 0.8598\n",
            "Epoch 331/400\n",
            "7/7 [==============================] - 3s 318ms/step - loss: 0.5301 - accuracy: 0.8633\n",
            "Epoch 332/400\n",
            "7/7 [==============================] - 3s 318ms/step - loss: 0.4958 - accuracy: 0.8778\n",
            "Epoch 333/400\n",
            "7/7 [==============================] - 3s 319ms/step - loss: 0.5164 - accuracy: 0.9091\n",
            "Epoch 334/400\n",
            "7/7 [==============================] - 3s 316ms/step - loss: 0.5302 - accuracy: 0.8938\n",
            "Epoch 335/400\n",
            "7/7 [==============================] - 3s 318ms/step - loss: 0.5182 - accuracy: 0.8745\n",
            "Epoch 336/400\n",
            "7/7 [==============================] - 3s 318ms/step - loss: 0.5277 - accuracy: 0.9016\n",
            "Epoch 337/400\n",
            "7/7 [==============================] - 3s 317ms/step - loss: 0.5117 - accuracy: 0.9044\n",
            "Epoch 338/400\n",
            "7/7 [==============================] - 3s 318ms/step - loss: 0.5107 - accuracy: 0.8771\n",
            "Epoch 339/400\n",
            "7/7 [==============================] - 3s 321ms/step - loss: 0.5226 - accuracy: 0.8866\n",
            "Epoch 340/400\n",
            "7/7 [==============================] - 3s 317ms/step - loss: 0.5215 - accuracy: 0.8827\n",
            "Epoch 341/400\n",
            "7/7 [==============================] - 3s 318ms/step - loss: 0.5161 - accuracy: 0.8705\n",
            "Epoch 342/400\n",
            "7/7 [==============================] - 3s 319ms/step - loss: 0.5261 - accuracy: 0.8360\n",
            "Epoch 343/400\n",
            "7/7 [==============================] - 2s 316ms/step - loss: 0.5345 - accuracy: 0.8842\n",
            "Epoch 344/400\n",
            "7/7 [==============================] - 3s 316ms/step - loss: 0.5074 - accuracy: 0.8947\n",
            "Epoch 345/400\n",
            "7/7 [==============================] - 3s 318ms/step - loss: 0.5308 - accuracy: 0.8823\n",
            "Epoch 346/400\n",
            "7/7 [==============================] - 3s 317ms/step - loss: 0.4880 - accuracy: 0.8878\n",
            "Epoch 347/400\n",
            "7/7 [==============================] - 3s 316ms/step - loss: 0.4918 - accuracy: 0.9256\n",
            "Epoch 348/400\n",
            "7/7 [==============================] - 3s 317ms/step - loss: 0.5321 - accuracy: 0.8786\n",
            "Epoch 349/400\n",
            "7/7 [==============================] - 3s 316ms/step - loss: 0.5290 - accuracy: 0.8652\n",
            "Epoch 350/400\n",
            "7/7 [==============================] - 3s 316ms/step - loss: 0.4902 - accuracy: 0.9166\n",
            "Epoch 351/400\n",
            "7/7 [==============================] - 3s 317ms/step - loss: 0.5246 - accuracy: 0.9012\n",
            "Epoch 352/400\n",
            "7/7 [==============================] - 3s 317ms/step - loss: 0.4689 - accuracy: 0.9053\n",
            "Epoch 353/400\n",
            "7/7 [==============================] - 3s 317ms/step - loss: 0.5302 - accuracy: 0.8859\n",
            "Epoch 354/400\n",
            "7/7 [==============================] - 3s 316ms/step - loss: 0.4836 - accuracy: 0.8921\n",
            "Epoch 355/400\n",
            "7/7 [==============================] - 3s 317ms/step - loss: 0.5311 - accuracy: 0.8806\n",
            "Epoch 356/400\n",
            "7/7 [==============================] - 3s 318ms/step - loss: 0.4933 - accuracy: 0.8877\n",
            "Epoch 357/400\n",
            "7/7 [==============================] - 3s 318ms/step - loss: 0.5166 - accuracy: 0.8590\n",
            "Epoch 358/400\n",
            "7/7 [==============================] - 3s 319ms/step - loss: 0.5218 - accuracy: 0.8384\n",
            "Epoch 359/400\n",
            "7/7 [==============================] - 3s 319ms/step - loss: 0.5012 - accuracy: 0.8943\n",
            "Epoch 360/400\n",
            "7/7 [==============================] - 3s 318ms/step - loss: 0.5081 - accuracy: 0.8630\n",
            "Epoch 361/400\n",
            "7/7 [==============================] - 3s 317ms/step - loss: 0.5044 - accuracy: 0.9025\n",
            "Epoch 362/400\n",
            "7/7 [==============================] - 3s 316ms/step - loss: 0.4874 - accuracy: 0.9197\n",
            "Epoch 363/400\n",
            "7/7 [==============================] - 3s 318ms/step - loss: 0.4793 - accuracy: 0.8794\n",
            "Epoch 364/400\n",
            "7/7 [==============================] - 3s 318ms/step - loss: 0.4803 - accuracy: 0.9136\n",
            "Epoch 365/400\n",
            "7/7 [==============================] - 3s 318ms/step - loss: 0.4782 - accuracy: 0.9013\n",
            "Epoch 366/400\n",
            "7/7 [==============================] - 3s 317ms/step - loss: 0.5165 - accuracy: 0.8646\n",
            "Epoch 367/400\n",
            "7/7 [==============================] - 2s 314ms/step - loss: 0.5065 - accuracy: 0.8971\n",
            "Epoch 368/400\n",
            "7/7 [==============================] - 3s 320ms/step - loss: 0.4804 - accuracy: 0.9080\n",
            "Epoch 369/400\n",
            "7/7 [==============================] - 3s 316ms/step - loss: 0.5126 - accuracy: 0.8610\n",
            "Epoch 370/400\n",
            "7/7 [==============================] - 3s 319ms/step - loss: 0.4884 - accuracy: 0.8929\n",
            "Epoch 371/400\n",
            "7/7 [==============================] - 3s 317ms/step - loss: 0.4987 - accuracy: 0.9090\n",
            "Epoch 372/400\n",
            "7/7 [==============================] - 3s 319ms/step - loss: 0.5068 - accuracy: 0.8803\n",
            "Epoch 373/400\n",
            "7/7 [==============================] - 3s 318ms/step - loss: 0.5458 - accuracy: 0.8604\n",
            "Epoch 374/400\n",
            "7/7 [==============================] - 3s 318ms/step - loss: 0.4783 - accuracy: 0.9217\n",
            "Epoch 375/400\n",
            "7/7 [==============================] - 3s 318ms/step - loss: 0.4847 - accuracy: 0.9289\n",
            "Epoch 376/400\n",
            "7/7 [==============================] - 3s 317ms/step - loss: 0.4678 - accuracy: 0.8970\n",
            "Epoch 377/400\n",
            "7/7 [==============================] - 3s 319ms/step - loss: 0.4835 - accuracy: 0.8773\n",
            "Epoch 378/400\n",
            "7/7 [==============================] - 3s 317ms/step - loss: 0.4992 - accuracy: 0.8780\n",
            "Epoch 379/400\n",
            "7/7 [==============================] - 3s 318ms/step - loss: 0.4869 - accuracy: 0.9072\n",
            "Epoch 380/400\n",
            "7/7 [==============================] - 3s 319ms/step - loss: 0.4815 - accuracy: 0.8846\n",
            "Epoch 381/400\n",
            "7/7 [==============================] - 3s 317ms/step - loss: 0.4920 - accuracy: 0.9061\n",
            "Epoch 382/400\n",
            "7/7 [==============================] - 3s 318ms/step - loss: 0.5233 - accuracy: 0.8387\n",
            "Epoch 383/400\n",
            "7/7 [==============================] - 3s 319ms/step - loss: 0.5243 - accuracy: 0.8578\n",
            "Epoch 384/400\n",
            "7/7 [==============================] - 3s 320ms/step - loss: 0.5072 - accuracy: 0.8360\n",
            "Epoch 385/400\n",
            "7/7 [==============================] - 3s 319ms/step - loss: 0.4939 - accuracy: 0.8814\n",
            "Epoch 386/400\n",
            "7/7 [==============================] - 3s 317ms/step - loss: 0.4421 - accuracy: 0.9226\n",
            "Epoch 387/400\n",
            "7/7 [==============================] - 3s 318ms/step - loss: 0.4976 - accuracy: 0.8632\n",
            "Epoch 388/400\n",
            "7/7 [==============================] - 3s 318ms/step - loss: 0.4747 - accuracy: 0.8856\n",
            "Epoch 389/400\n",
            "7/7 [==============================] - 3s 317ms/step - loss: 0.5082 - accuracy: 0.8590\n",
            "Epoch 390/400\n",
            "7/7 [==============================] - 3s 318ms/step - loss: 0.4693 - accuracy: 0.9156\n",
            "Epoch 391/400\n",
            "7/7 [==============================] - 3s 318ms/step - loss: 0.4989 - accuracy: 0.8670\n",
            "Epoch 392/400\n",
            "7/7 [==============================] - 3s 317ms/step - loss: 0.5390 - accuracy: 0.8334\n",
            "Epoch 393/400\n",
            "7/7 [==============================] - 3s 316ms/step - loss: 0.4865 - accuracy: 0.8450\n",
            "Epoch 394/400\n",
            "7/7 [==============================] - 2s 315ms/step - loss: 0.4821 - accuracy: 0.9267\n",
            "Epoch 395/400\n",
            "7/7 [==============================] - 3s 317ms/step - loss: 0.4868 - accuracy: 0.9053\n",
            "Epoch 396/400\n",
            "7/7 [==============================] - 3s 315ms/step - loss: 0.4998 - accuracy: 0.8778\n",
            "Epoch 397/400\n",
            "7/7 [==============================] - 3s 317ms/step - loss: 0.4749 - accuracy: 0.9048\n",
            "Epoch 398/400\n",
            "7/7 [==============================] - 3s 317ms/step - loss: 0.4969 - accuracy: 0.8690\n",
            "Epoch 399/400\n",
            "7/7 [==============================] - 3s 317ms/step - loss: 0.5295 - accuracy: 0.8496\n",
            "Epoch 400/400\n",
            "7/7 [==============================] - 3s 318ms/step - loss: 0.4609 - accuracy: 0.8842\n",
            "INFO:tensorflow:Assets written to: /content/model/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1pU9LG4jwYcU"
      },
      "source": [
        "hist_acc = history.history['accuracy']\r\n",
        "hist_loss = history.history['loss']"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "id": "Ej0IYDTCLzEH",
        "outputId": "0943d870-d892-4a61-e58d-e451a48e1c54"
      },
      "source": [
        "# plot the loss and accuracy curves\r\n",
        "plt.plot( hist_loss)\r\n",
        "plt.title('model loss')\r\n",
        "plt.ylabel('loss')\r\n",
        "plt.xlabel('epoch')\r\n",
        "plt.show()\r\n",
        "plt.plot( hist_acc )\r\n",
        "plt.title('model accuracy')\r\n",
        "plt.ylabel('accuracy')\r\n",
        "plt.xlabel('epoch')\r\n",
        "plt.show()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_G0UZGkLzEI"
      },
      "source": [
        "### Fine Tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJ8izmDaLzEI"
      },
      "source": [
        "In the feature extraction, you were only training a few layers on top of a base model. The weights of the pre-trained network were not updated during training.\r\n",
        "\r\n",
        "One way to increase performance even further is to train (or \"fine-tune\") the weights of the top layers of the pre-trained model alongside the training of the classifier you added. The training process will force the weights to be tuned from generic feature maps to features associated specifically with the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKo8wHKFLzEI"
      },
      "source": [
        "# unfreeze the base model\r\n",
        "base_model.trainable = True\r\n",
        "fine_tune_at = 100\r\n",
        "\r\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TyjSf1pmLzEJ",
        "outputId": "dc1432e3-e7d0-45db-cab7-98bc974134be"
      },
      "source": [
        "# print the number of layers in the base model\r\n",
        "print(base_model.layers)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[<tensorflow.python.keras.engine.input_layer.InputLayer object at 0x7fddf191dc50>, <tensorflow.python.keras.layers.preprocessing.image_preprocessing.Rescaling object at 0x7fddf0c4cf90>, <tensorflow.python.keras.layers.preprocessing.normalization.Normalization object at 0x7fddf0c03b10>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x7fddf0c03990>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fddf0c22bd0>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fddf0beaa10>, <tensorflow.python.keras.layers.core.Activation object at 0x7fddf0becfd0>, <tensorflow.python.keras.layers.convolutional.DepthwiseConv2D object at 0x7fddf0b9ebd0>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fddf0b9ad10>, <tensorflow.python.keras.layers.core.Activation object at 0x7fddf0b37c10>, <tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D object at 0x7fddf0bec790>, <tensorflow.python.keras.layers.core.Reshape object at 0x7fddf0b40e50>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fddf0b4cdd0>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fddf0b4e210>, <tensorflow.python.keras.layers.merge.Multiply object at 0x7fddf0b5cc90>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fddf0b61410>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fddf0b5ce50>, <tensorflow.python.keras.layers.convolutional.DepthwiseConv2D object at 0x7fddf0b6ce10>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fddf0b5cbd0>, <tensorflow.python.keras.layers.core.Activation object at 0x7fddf0b68790>, <tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D object at 0x7fddf0afc550>, <tensorflow.python.keras.layers.core.Reshape object at 0x7fddf0b0dc50>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fddf0b0dfd0>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fddf0b13a90>, <tensorflow.python.keras.layers.merge.Multiply object at 0x7fddf0b1ec90>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fddf0b21090>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fddf0b6cf50>, <tensorflow.python.keras.layers.core.Dropout object at 0x7fddf0b68210>, <tensorflow.python.keras.layers.merge.Add object at 0x7fddf0b45a10>, <tensorflow.python.keras.layers.convolutional.DepthwiseConv2D object at 0x7fddf0becb50>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fddf0b13110>, <tensorflow.python.keras.layers.core.Activation object at 0x7fddf0b060d0>, <tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D object at 0x7fddf0b2bbd0>, <tensorflow.python.keras.layers.core.Reshape object at 0x7fddf0b24050>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fddf0ab1850>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fddf0ac0110>, <tensorflow.python.keras.layers.merge.Multiply object at 0x7fddf0ab13d0>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fddf0b2c750>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fddf0ac8f90>, <tensorflow.python.keras.layers.core.Dropout object at 0x7fddf0ad0b90>, <tensorflow.python.keras.layers.merge.Add object at 0x7fddf0ad5a90>, <tensorflow.python.keras.layers.convolutional.DepthwiseConv2D object at 0x7fddf0adc750>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fddf0ae4810>, <tensorflow.python.keras.layers.core.Activation object at 0x7fddf0ae6f50>, <tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D object at 0x7fddf0ae0210>, <tensorflow.python.keras.layers.core.Reshape object at 0x7fddf0a75c50>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fddf0a78810>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fddf0a7f790>, <tensorflow.python.keras.layers.merge.Multiply object at 0x7fddf0a83c90>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fddf0a8bcd0>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fddf0a95a10>, <tensorflow.python.keras.layers.core.Dropout object at 0x7fddf0a88050>, <tensorflow.python.keras.layers.merge.Add object at 0x7fddf0a9fd10>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fddf0aa6490>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fddf0aabcd0>, <tensorflow.python.keras.layers.core.Activation object at 0x7fddf0a9ad10>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x7fddf0aa0610>, <tensorflow.python.keras.layers.convolutional.DepthwiseConv2D object at 0x7fddf0a3ae90>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fddf0a32250>, <tensorflow.python.keras.layers.core.Activation object at 0x7fddf0a3ff90>, <tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D object at 0x7fddf0a3df10>, <tensorflow.python.keras.layers.core.Reshape object at 0x7fddf0a4c190>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fddf0a51f90>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fddf0a5d090>, <tensorflow.python.keras.layers.merge.Multiply object at 0x7fddf0a67a90>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fddf0a51890>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fddf09f17d0>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fddf09fafd0>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fddf0a6da50>, <tensorflow.python.keras.layers.core.Activation object at 0x7fddf0a3f350>, <tensorflow.python.keras.layers.convolutional.DepthwiseConv2D object at 0x7fddf0adc5d0>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fddf0acb750>, <tensorflow.python.keras.layers.core.Activation object at 0x7fddf0ac3990>, <tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D object at 0x7fddf0b3c090>, <tensorflow.python.keras.layers.core.Reshape object at 0x7fddf0a08e10>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fddf0a0cd10>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fddf0a13f10>, <tensorflow.python.keras.layers.merge.Multiply object at 0x7fddf0a18990>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fddf0a20410>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fddf0a24bd0>, <tensorflow.python.keras.layers.core.Dropout object at 0x7fddf0a18ed0>, <tensorflow.python.keras.layers.merge.Add object at 0x7fddf0a2f590>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fddf09b3b90>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fddf09ba6d0>, <tensorflow.python.keras.layers.core.Activation object at 0x7fddf0a1c7d0>, <tensorflow.python.keras.layers.convolutional.DepthwiseConv2D object at 0x7fddf09bb7d0>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fddf09cad50>, <tensorflow.python.keras.layers.core.Activation object at 0x7fddf0a2ff50>, <tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D object at 0x7fddf09cfe90>, <tensorflow.python.keras.layers.core.Reshape object at 0x7fddf09e0f90>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fddf09e0dd0>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fddf09e5750>, <tensorflow.python.keras.layers.merge.Multiply object at 0x7fddf09eef90>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fddf09747d0>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fddf0976590>, <tensorflow.python.keras.layers.core.Dropout object at 0x7fddf0981f50>, <tensorflow.python.keras.layers.merge.Add object at 0x7fddf0988ed0>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fddf09884d0>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fddf0992ad0>, <tensorflow.python.keras.layers.core.Activation object at 0x7fddf0998d10>, <tensorflow.python.keras.layers.convolutional.DepthwiseConv2D object at 0x7fddf0992bd0>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fddf09a0e90>, <tensorflow.python.keras.layers.core.Activation object at 0x7fddf09a0f50>, <tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D object at 0x7fddf09ab390>, <tensorflow.python.keras.layers.core.Reshape object at 0x7fddf09a6210>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fddf09312d0>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fddf093c810>, <tensorflow.python.keras.layers.merge.Multiply object at 0x7fddf0931650>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fddf09a6890>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fddf09e5050>, <tensorflow.python.keras.layers.core.Dropout object at 0x7fddf09cad90>, <tensorflow.python.keras.layers.merge.Add object at 0x7fddf0987d10>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fddf0beadd0>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fddf0aa0450>, <tensorflow.python.keras.layers.core.Activation object at 0x7fddf094f750>, <tensorflow.python.keras.layers.convolutional.DepthwiseConv2D object at 0x7fddf0ab7a50>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fddf0956950>, <tensorflow.python.keras.layers.core.Activation object at 0x7fddf09582d0>, <tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D object at 0x7fddf0956dd0>, <tensorflow.python.keras.layers.core.Reshape object at 0x7fddf0969cd0>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fddf096d890>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdde039b810>, <tensorflow.python.keras.layers.merge.Multiply object at 0x7fdde03a5550>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdde03a6d50>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fdde03add90>, <tensorflow.python.keras.layers.core.Dropout object at 0x7fdde03b1e50>, <tensorflow.python.keras.layers.merge.Add object at 0x7fdde03b8d90>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdde03c2550>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fdde03c6d90>, <tensorflow.python.keras.layers.core.Activation object at 0x7fdde03a0f90>, <tensorflow.python.keras.layers.convolutional.DepthwiseConv2D object at 0x7fdde03cb710>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fdde03d5d90>, <tensorflow.python.keras.layers.core.Activation object at 0x7fdde03b8710>, <tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D object at 0x7fdde03d9450>, <tensorflow.python.keras.layers.core.Reshape object at 0x7fdde0369f90>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdde0369e90>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdde0375150>, <tensorflow.python.keras.layers.merge.Multiply object at 0x7fdde037eb10>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdde0382950>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fdde0386d50>, <tensorflow.python.keras.layers.core.Dropout object at 0x7fdde03908d0>, <tensorflow.python.keras.layers.merge.Add object at 0x7fdde031b990>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdde031b0d0>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fdde0386950>, <tensorflow.python.keras.layers.core.Activation object at 0x7fdde031e750>, <tensorflow.python.keras.layers.convolutional.DepthwiseConv2D object at 0x7fdde0390c10>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fdde032dc10>, <tensorflow.python.keras.layers.core.Activation object at 0x7fdde0335fd0>, <tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D object at 0x7fdde033a490>, <tensorflow.python.keras.layers.core.Reshape object at 0x7fdde0335190>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdde031b9d0>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdde03cbd90>, <tensorflow.python.keras.layers.merge.Multiply object at 0x7fdde031b490>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdde0339a90>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fddf0a1c550>, <tensorflow.python.keras.layers.core.Dropout object at 0x7fddf09d9210>, <tensorflow.python.keras.layers.merge.Add object at 0x7fddf09503d0>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdde0341cd0>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fdde0349990>, <tensorflow.python.keras.layers.core.Activation object at 0x7fdde034af90>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x7fddf09c0510>, <tensorflow.python.keras.layers.convolutional.DepthwiseConv2D object at 0x7fdde0348850>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fdde02dbe50>, <tensorflow.python.keras.layers.core.Activation object at 0x7fdde02dbb90>, <tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D object at 0x7fdde0358dd0>, <tensorflow.python.keras.layers.core.Reshape object at 0x7fdde02e9e90>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdde02f4110>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdde02f8e90>, <tensorflow.python.keras.layers.merge.Multiply object at 0x7fdde02fd490>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdde030c710>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fdde0311b90>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdde0312dd0>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fdde031ab90>, <tensorflow.python.keras.layers.core.Activation object at 0x7fdde0312550>, <tensorflow.python.keras.layers.convolutional.DepthwiseConv2D object at 0x7fdde02aeb90>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fdde02bb4d0>, <tensorflow.python.keras.layers.core.Activation object at 0x7fdde0311dd0>, <tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D object at 0x7fdde02c4dd0>, <tensorflow.python.keras.layers.core.Reshape object at 0x7fdde02c9d10>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdde02d0d90>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdde02d60d0>, <tensorflow.python.keras.layers.merge.Multiply object at 0x7fdde025e8d0>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdde0262850>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fdde0269b10>, <tensorflow.python.keras.layers.core.Dropout object at 0x7fdde0269d50>, <tensorflow.python.keras.layers.merge.Add object at 0x7fdde0278810>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdde027dd10>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fdde0266f50>, <tensorflow.python.keras.layers.core.Activation object at 0x7fdde0266850>, <tensorflow.python.keras.layers.convolutional.DepthwiseConv2D object at 0x7fdde028a4d0>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fdde028a810>, <tensorflow.python.keras.layers.core.Activation object at 0x7fdde0282410>, <tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D object at 0x7fdde02d0a50>, <tensorflow.python.keras.layers.core.Reshape object at 0x7fdde02d0510>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdde031a310>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdde02f8050>, <tensorflow.python.keras.layers.merge.Multiply object at 0x7fdde02c97d0>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdde02f4050>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fdde02d0650>, <tensorflow.python.keras.layers.core.Dropout object at 0x7fdde031bb10>, <tensorflow.python.keras.layers.merge.Add object at 0x7fdde034edd0>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdde03941d0>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fdde02bb3d0>, <tensorflow.python.keras.layers.core.Activation object at 0x7fdde028ed10>, <tensorflow.python.keras.layers.convolutional.DepthwiseConv2D object at 0x7fdde021c450>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fdde021e210>, <tensorflow.python.keras.layers.core.Activation object at 0x7fdde021cad0>, <tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D object at 0x7fdde0231ad0>, <tensorflow.python.keras.layers.core.Reshape object at 0x7fdde030c150>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdde0229350>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdde022da90>, <tensorflow.python.keras.layers.merge.Multiply object at 0x7fdde0231190>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdde0249d50>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fdde0255e50>, <tensorflow.python.keras.layers.core.Dropout object at 0x7fdde01dd150>, <tensorflow.python.keras.layers.merge.Add object at 0x7fdde032d150>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdde01dd490>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fdde0255950>, <tensorflow.python.keras.layers.core.Activation object at 0x7fdde01e9fd0>, <tensorflow.python.keras.layers.convolutional.DepthwiseConv2D object at 0x7fdde01ee610>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fdde01f3e10>, <tensorflow.python.keras.layers.core.Activation object at 0x7fdde01eeb50>, <tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D object at 0x7fdde01ee690>, <tensorflow.python.keras.layers.core.Reshape object at 0x7fdde0234c90>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdde0203c90>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdde019c210>, <tensorflow.python.keras.layers.merge.Multiply object at 0x7fdde020a510>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdde01a15d0>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fdde01f3c10>, <tensorflow.python.keras.layers.core.Dropout object at 0x7fdde01b27d0>, <tensorflow.python.keras.layers.merge.Add object at 0x7fdde01b25d0>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdde01ad0d0>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fdde01d09d0>, <tensorflow.python.keras.layers.core.Activation object at 0x7fdde01c9450>, <tensorflow.python.keras.layers.convolutional.DepthwiseConv2D object at 0x7fdde01c24d0>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fdde01b2bd0>, <tensorflow.python.keras.layers.core.Activation object at 0x7fdde01f82d0>, <tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D object at 0x7fdde020a190>, <tensorflow.python.keras.layers.core.Reshape object at 0x7fdde0214410>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdde01bca10>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdde022d7d0>, <tensorflow.python.keras.layers.merge.Multiply object at 0x7fdde024f2d0>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdde01a87d0>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fdde032d3d0>, <tensorflow.python.keras.layers.core.Dropout object at 0x7fdde01f8590>, <tensorflow.python.keras.layers.merge.Add object at 0x7fdde01d4210>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdde0282a10>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fdde0282590>, <tensorflow.python.keras.layers.core.Activation object at 0x7fdde016cdd0>, <tensorflow.python.keras.layers.convolutional.DepthwiseConv2D object at 0x7fdde0163250>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fdde0160a50>, <tensorflow.python.keras.layers.core.Activation object at 0x7fdde016c5d0>, <tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D object at 0x7fdde0179d50>, <tensorflow.python.keras.layers.core.Reshape object at 0x7fdde025ab50>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdde0173450>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdde0189fd0>, <tensorflow.python.keras.layers.merge.Multiply object at 0x7fdde017dfd0>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdde0197410>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fdde0160890>, <tensorflow.python.keras.layers.core.Dropout object at 0x7fdde0129610>, <tensorflow.python.keras.layers.merge.Add object at 0x7fdde0129990>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdde031b310>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fdde013b8d0>, <tensorflow.python.keras.layers.core.Activation object at 0x7fdde0138ed0>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x7fdde0138550>, <tensorflow.python.keras.layers.convolutional.DepthwiseConv2D object at 0x7fdde01455d0>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fdde0147610>, <tensorflow.python.keras.layers.core.Activation object at 0x7fdde0138390>, <tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D object at 0x7fdde011de10>, <tensorflow.python.keras.layers.core.Reshape object at 0x7fdde00e51d0>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdde0159390>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdde00e0a90>, <tensorflow.python.keras.layers.merge.Multiply object at 0x7fdde00f6850>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdde00ed890>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fdde00e0cd0>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdde010be50>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fdde0106d10>, <tensorflow.python.keras.layers.core.Activation object at 0x7fdde0106a90>, <tensorflow.python.keras.layers.convolutional.DepthwiseConv2D object at 0x7fdde0101d50>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fdde00e5310>, <tensorflow.python.keras.layers.core.Activation object at 0x7fdde0147510>, <tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D object at 0x7fdde010bf90>, <tensorflow.python.keras.layers.core.Reshape object at 0x7fdde00e5950>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdde0163710>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdde01c23d0>, <tensorflow.python.keras.layers.merge.Multiply object at 0x7fdde0154790>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdde0118a10>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fdde009c8d0>, <tensorflow.python.keras.layers.core.Dropout object at 0x7fdde00ed990>, <tensorflow.python.keras.layers.merge.Add object at 0x7fdde00a5b90>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdde0129410>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fdde00a5450>, <tensorflow.python.keras.layers.core.Activation object at 0x7fdde00a9710>, <tensorflow.python.keras.layers.convolutional.DepthwiseConv2D object at 0x7fdde00c3150>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fdde00c4550>, <tensorflow.python.keras.layers.core.Activation object at 0x7fdde00c92d0>, <tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D object at 0x7fdde00c99d0>, <tensorflow.python.keras.layers.core.Reshape object at 0x7fdde01e1510>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdde00d4810>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdde00a9b90>, <tensorflow.python.keras.layers.merge.Multiply object at 0x7fdde00d1f90>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdde0066ad0>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fdde0073b90>, <tensorflow.python.keras.layers.core.Dropout object at 0x7fdde007e950>, <tensorflow.python.keras.layers.merge.Add object at 0x7fdde007a9d0>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdde00a5e50>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fdde007eb90>, <tensorflow.python.keras.layers.core.Activation object at 0x7fdde007e990>, <tensorflow.python.keras.layers.convolutional.DepthwiseConv2D object at 0x7fdde008bd90>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fdde005ed50>, <tensorflow.python.keras.layers.core.Activation object at 0x7fdde008f750>, <tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D object at 0x7fdde001ba10>, <tensorflow.python.keras.layers.core.Reshape object at 0x7fdde002bb50>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdde002bfd0>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdde0039e10>, <tensorflow.python.keras.layers.merge.Multiply object at 0x7fdde008fe50>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdde00303d0>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fdde0046d50>, <tensorflow.python.keras.layers.core.Dropout object at 0x7fdde005a650>, <tensorflow.python.keras.layers.merge.Add object at 0x7fdda414ca10>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdde0097090>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fdde0097a50>, <tensorflow.python.keras.layers.core.Activation object at 0x7fdde0073050>, <tensorflow.python.keras.layers.convolutional.DepthwiseConv2D object at 0x7fddf0beae90>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fde0f8b38d0>, <tensorflow.python.keras.layers.core.Activation object at 0x7fddf0afb290>, <tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D object at 0x7fddf0bec710>, <tensorflow.python.keras.layers.core.Reshape object at 0x7fddf0a6d890>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fddf0a8bdd0>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fddf09cfc50>, <tensorflow.python.keras.layers.merge.Multiply object at 0x7fddf0a2fed0>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fddf09e5a50>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fddf0a95590>, <tensorflow.python.keras.layers.core.Dropout object at 0x7fdde03b1a50>, <tensorflow.python.keras.layers.merge.Add object at 0x7fdde037ec90>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fddf09697d0>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fddf0988b50>, <tensorflow.python.keras.layers.core.Activation object at 0x7fddf0952910>, <tensorflow.python.keras.layers.convolutional.DepthwiseConv2D object at 0x7fdde03d9510>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fdde039b750>, <tensorflow.python.keras.layers.core.Activation object at 0x7fddf09500d0>, <tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D object at 0x7fdde02e9ed0>, <tensorflow.python.keras.layers.core.Reshape object at 0x7fdde034e090>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdde02ae190>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdde0278590>, <tensorflow.python.keras.layers.merge.Multiply object at 0x7fdde03587d0>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdde02db850>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fdde0101c90>, <tensorflow.python.keras.layers.core.Dropout object at 0x7fddf09a0bd0>, <tensorflow.python.keras.layers.merge.Add object at 0x7fddf0a58650>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fddf09f1e50>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fddf0b21450>, <tensorflow.python.keras.layers.core.Activation object at 0x7fddf0caab50>, <tensorflow.python.keras.layers.convolutional.DepthwiseConv2D object at 0x7fddf0a02990>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fdde00ba990>, <tensorflow.python.keras.layers.core.Activation object at 0x7fdde009ed50>, <tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D object at 0x7fdde0348210>, <tensorflow.python.keras.layers.core.Reshape object at 0x7fdde0197150>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdda414d550>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdda4145850>, <tensorflow.python.keras.layers.merge.Multiply object at 0x7fdda40c9450>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdda40d1e50>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fdda40db690>, <tensorflow.python.keras.layers.core.Dropout object at 0x7fdda40c9190>, <tensorflow.python.keras.layers.merge.Add object at 0x7fddf0a02b10>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdde0055ed0>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fdde01d0510>, <tensorflow.python.keras.layers.core.Activation object at 0x7fddf09f1550>, <tensorflow.python.keras.layers.convolutional.DepthwiseConv2D object at 0x7fddf094fbd0>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fddf0a679d0>, <tensorflow.python.keras.layers.core.Activation object at 0x7fddf0af4cd0>, <tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D object at 0x7fdda40e0690>, <tensorflow.python.keras.layers.core.Reshape object at 0x7fdda40e8dd0>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdda40e8a10>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdda40ece90>, <tensorflow.python.keras.layers.merge.Multiply object at 0x7fdda40f9490>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdda40fded0>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fdda41046d0>, <tensorflow.python.keras.layers.core.Dropout object at 0x7fdda4088c50>, <tensorflow.python.keras.layers.merge.Add object at 0x7fdda4090d10>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdda40902d0>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fdda4095410>, <tensorflow.python.keras.layers.core.Activation object at 0x7fdda409ae50>, <tensorflow.python.keras.layers.convolutional.DepthwiseConv2D object at 0x7fdda4104dd0>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fdda4090fd0>, <tensorflow.python.keras.layers.core.Activation object at 0x7fdda40a5cd0>, <tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D object at 0x7fdda40b5050>, <tensorflow.python.keras.layers.core.Reshape object at 0x7fdda40b0e50>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdda40a5350>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdda40c0b10>, <tensorflow.python.keras.layers.merge.Multiply object at 0x7fdda40c0110>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdda40b0fd0>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fdda40537d0>, <tensorflow.python.keras.layers.core.Dropout object at 0x7fdda4059fd0>, <tensorflow.python.keras.layers.merge.Add object at 0x7fdda40534d0>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdda405add0>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fdda406a690>, <tensorflow.python.keras.layers.core.Activation object at 0x7fdda406f910>, <tensorflow.python.keras.layers.convolutional.DepthwiseConv2D object at 0x7fdda40636d0>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fdda4079b90>, <tensorflow.python.keras.layers.core.Activation object at 0x7fdda40091d0>, <tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D object at 0x7fdda40834d0>, <tensorflow.python.keras.layers.core.Reshape object at 0x7fdda4013f50>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdda4019a50>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdda401f910>, <tensorflow.python.keras.layers.merge.Multiply object at 0x7fdda4083d90>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdda4056790>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fdda4047090>, <tensorflow.python.keras.layers.core.Dropout object at 0x7fdda4053450>, <tensorflow.python.keras.layers.merge.Add object at 0x7fdda40f9210>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fddf0ac3e10>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fddf0b24890>, <tensorflow.python.keras.layers.core.Activation object at 0x7fdda40fde50>, <tensorflow.python.keras.layers.convolutional.DepthwiseConv2D object at 0x7fdda4022590>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fdda402dd10>, <tensorflow.python.keras.layers.core.Activation object at 0x7fdda40e3490>, <tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D object at 0x7fdda4030550>, <tensorflow.python.keras.layers.core.Reshape object at 0x7fdda403ec50>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdda403e690>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdda4042ad0>, <tensorflow.python.keras.layers.merge.Multiply object at 0x7fdd93fc5550>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdd93fc8d50>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fdd93fd6990>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdd93fbc650>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fdd93fe2110>, <tensorflow.python.keras.layers.core.Activation object at 0x7fdd93fe8fd0>, <tensorflow.python.keras.layers.convolutional.DepthwiseConv2D object at 0x7fdd93fcfa50>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fdd93ff9750>, <tensorflow.python.keras.layers.core.Activation object at 0x7fdd93f80d90>, <tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D object at 0x7fdd93f8b210>, <tensorflow.python.keras.layers.core.Reshape object at 0x7fdd93f8b2d0>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdd93f80650>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdd93f98510>, <tensorflow.python.keras.layers.merge.Multiply object at 0x7fdd93f80410>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdd93f87950>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fdd93fa6c90>, <tensorflow.python.keras.layers.core.Dropout object at 0x7fdd93faec10>, <tensorflow.python.keras.layers.merge.Add object at 0x7fdd93fb2fd0>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdd93fb6850>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fdd93f40f50>, <tensorflow.python.keras.layers.core.Activation object at 0x7fdd93f43e90>, <tensorflow.python.keras.layers.convolutional.DepthwiseConv2D object at 0x7fdd93f408d0>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fdd93f57610>, <tensorflow.python.keras.layers.core.Activation object at 0x7fdd93f5ce50>, <tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D object at 0x7fdd93f57990>, <tensorflow.python.keras.layers.core.Reshape object at 0x7fdd93fb2c90>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdd93f80090>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdd93fc5b10>, <tensorflow.python.keras.layers.merge.Multiply object at 0x7fdd93fc89d0>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdda40363d0>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fdda40e3550>, <tensorflow.python.keras.layers.core.Dropout object at 0x7fdda403e610>, <tensorflow.python.keras.layers.merge.Add object at 0x7fdd93f5ae90>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdd93f66650>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fdd93f6a6d0>, <tensorflow.python.keras.layers.core.Activation object at 0x7fdda40364d0>, <tensorflow.python.keras.layers.convolutional.DepthwiseConv2D object at 0x7fdd93f6c810>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fdd93f77e90>, <tensorflow.python.keras.layers.core.Activation object at 0x7fdd93f7be10>, <tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D object at 0x7fdd93effa50>, <tensorflow.python.keras.layers.core.Reshape object at 0x7fdd93f07b90>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdd93f0e1d0>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdd93f15210>, <tensorflow.python.keras.layers.merge.Multiply object at 0x7fdd93f1ce90>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdd93f1c890>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fdd93f25c90>, <tensorflow.python.keras.layers.core.Dropout object at 0x7fdd93f25e50>, <tensorflow.python.keras.layers.merge.Add object at 0x7fdd93f37ad0>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdd93f37150>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fdd93f25a50>, <tensorflow.python.keras.layers.core.Activation object at 0x7fdd93ebe890>, <tensorflow.python.keras.layers.convolutional.DepthwiseConv2D object at 0x7fdd93f2f5d0>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fdd93ecddd0>, <tensorflow.python.keras.layers.core.Activation object at 0x7fdd93ed1ed0>, <tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D object at 0x7fdd93ed6d90>, <tensorflow.python.keras.layers.core.Reshape object at 0x7fdd93ed1190>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdd93ede590>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdd93ee7150>, <tensorflow.python.keras.layers.merge.Multiply object at 0x7fdd93edec10>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdd93ed4bd0>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fdd93ef7d90>, <tensorflow.python.keras.layers.core.Dropout object at 0x7fdd93efa410>, <tensorflow.python.keras.layers.merge.Add object at 0x7fdd93e83e10>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdd93e855d0>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fdd93e92c50>, <tensorflow.python.keras.layers.core.Activation object at 0x7fdd93e9d990>, <tensorflow.python.keras.layers.convolutional.DepthwiseConv2D object at 0x7fdd93e925d0>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fdd93eee910>, <tensorflow.python.keras.layers.core.Activation object at 0x7fdd93f07ad0>, <tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D object at 0x7fdd93f32250>, <tensorflow.python.keras.layers.core.Reshape object at 0x7fdda405a950>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdd93ea1810>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdd93ea3f10>, <tensorflow.python.keras.layers.merge.Multiply object at 0x7fdd93ea6c90>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdd93eabcd0>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fdd93eb4a10>, <tensorflow.python.keras.layers.core.Dropout object at 0x7fdd93eaa050>, <tensorflow.python.keras.layers.merge.Add object at 0x7fdd93e3dd10>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdd93e434d0>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fdd93e48d10>, <tensorflow.python.keras.layers.core.Activation object at 0x7fdd93eb9690>, <tensorflow.python.keras.layers.convolutional.DepthwiseConv2D object at 0x7fdd93e4d690>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fdd93e56d10>, <tensorflow.python.keras.layers.core.Activation object at 0x7fdd93e3d7d0>, <tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D object at 0x7fdd93e5d850>, <tensorflow.python.keras.layers.core.Reshape object at 0x7fdd93e6ce90>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdd93e64090>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdd93e77210>, <tensorflow.python.keras.layers.merge.Multiply object at 0x7fdd93e7aa50>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdd93e02c50>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fdd93e09fd0>, <tensorflow.python.keras.layers.core.Dropout object at 0x7fdd93e12890>, <tensorflow.python.keras.layers.merge.Add object at 0x7fdd93e13ed0>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdd93e13790>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fdd93e09690>, <tensorflow.python.keras.layers.core.Activation object at 0x7fdd93e0d150>, <tensorflow.python.keras.layers.convolutional.DepthwiseConv2D object at 0x7fdd93e28790>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fdd93e28f90>, <tensorflow.python.keras.layers.core.Activation object at 0x7fdd93e208d0>, <tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D object at 0x7fdd93e1c950>, <tensorflow.python.keras.layers.core.Reshape object at 0x7fdd93e39f90>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdd93e393d0>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdd93e1c510>, <tensorflow.python.keras.layers.merge.Multiply object at 0x7fdd93dd6890>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdd93e39190>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fdd93dd6410>, <tensorflow.python.keras.layers.core.Dropout object at 0x7fdd93ddecd0>, <tensorflow.python.keras.layers.merge.Add object at 0x7fdd93e0d7d0>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdd93dcb190>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fdd93e13a10>, <tensorflow.python.keras.layers.core.Activation object at 0x7fdd93dde950>, <tensorflow.python.keras.layers.convolutional.DepthwiseConv2D object at 0x7fdd93e4f510>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fdd93e39550>, <tensorflow.python.keras.layers.core.Activation object at 0x7fdd93deb750>, <tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D object at 0x7fdd93f200d0>, <tensorflow.python.keras.layers.core.Reshape object at 0x7fdd93e39910>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdd93defcd0>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdd93d7c850>, <tensorflow.python.keras.layers.merge.Multiply object at 0x7fdd93deb250>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdd93dd6f50>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fdd93df0ad0>, <tensorflow.python.keras.layers.core.Dropout object at 0x7fdd93d96a90>, <tensorflow.python.keras.layers.merge.Add object at 0x7fdd93e29ad0>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdd93d96e50>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fdd93d90050>, <tensorflow.python.keras.layers.core.Activation object at 0x7fdd93d967d0>, <tensorflow.python.keras.layers.convolutional.DepthwiseConv2D object at 0x7fdd93da4d10>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fdd93df0b90>, <tensorflow.python.keras.layers.core.Activation object at 0x7fdd93da7b50>, <tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D object at 0x7fdd93df0790>, <tensorflow.python.keras.layers.core.Reshape object at 0x7fdd93df06d0>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdd93db7f50>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdd93d587d0>, <tensorflow.python.keras.layers.merge.Multiply object at 0x7fdd93d3dc50>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdd93d58290>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fdd93da7ed0>, <tensorflow.python.keras.layers.core.Dropout object at 0x7fdd93db78d0>, <tensorflow.python.keras.layers.merge.Add object at 0x7fdd93d5de10>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdd93d73c10>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fdd93d6f7d0>, <tensorflow.python.keras.layers.core.Activation object at 0x7fdd93d65e10>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x7fdd93d65e50>, <tensorflow.python.keras.layers.convolutional.DepthwiseConv2D object at 0x7fdd93d76550>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fdd93d17750>, <tensorflow.python.keras.layers.core.Activation object at 0x7fdd93d17fd0>, <tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D object at 0x7fdd93d06190>, <tensorflow.python.keras.layers.core.Reshape object at 0x7fdd93d48c10>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdd93d76350>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdd93d21cd0>, <tensorflow.python.keras.layers.merge.Multiply object at 0x7fdd93d1c910>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdd93cc1fd0>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fdd93d25a50>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdd93d2ea10>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fdd93d070d0>, <tensorflow.python.keras.layers.core.Activation object at 0x7fdd93cbeb10>, <tensorflow.python.keras.layers.convolutional.DepthwiseConv2D object at 0x7fdd93d41290>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fdd93d2e7d0>, <tensorflow.python.keras.layers.core.Activation object at 0x7fdd93d17050>, <tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D object at 0x7fdd93d0d5d0>, <tensorflow.python.keras.layers.core.Reshape object at 0x7fdd93d96e90>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdd93d87e90>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdd93cd00d0>, <tensorflow.python.keras.layers.merge.Multiply object at 0x7fdd93deb690>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdd93cc8d90>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fdd93d8c390>, <tensorflow.python.keras.layers.core.Dropout object at 0x7fdd93ce27d0>, <tensorflow.python.keras.layers.merge.Add object at 0x7fdd93ce2490>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdd93cdea10>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fdd93ce6cd0>, <tensorflow.python.keras.layers.core.Activation object at 0x7fdd93ce62d0>, <tensorflow.python.keras.layers.convolutional.DepthwiseConv2D object at 0x7fdd93cf3e50>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fdd93cc89d0>, <tensorflow.python.keras.layers.core.Activation object at 0x7fdd93c88d90>, <tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D object at 0x7fdd93c88dd0>, <tensorflow.python.keras.layers.core.Reshape object at 0x7fdd93cc84d0>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdd93ce21d0>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdd93c9ea50>, <tensorflow.python.keras.layers.merge.Multiply object at 0x7fdd93c8cbd0>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdd93cda690>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fdd93caff90>, <tensorflow.python.keras.layers.core.Dropout object at 0x7fdd93cb7890>, <tensorflow.python.keras.layers.merge.Add object at 0x7fdd93cb7c10>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdd93ce2790>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fdd93c438d0>, <tensorflow.python.keras.layers.core.Activation object at 0x7fdd93c43e10>, <tensorflow.python.keras.layers.convolutional.DepthwiseConv2D object at 0x7fdd93cb7210>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fdd93c57190>, <tensorflow.python.keras.layers.core.Activation object at 0x7fdd93c60050>, <tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D object at 0x7fdd93c60290>, <tensorflow.python.keras.layers.core.Reshape object at 0x7fdd93c98410>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdd93c834d0>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdd93c76890>, <tensorflow.python.keras.layers.merge.Multiply object at 0x7fdd93c62590>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdd93c0a710>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fdd93c0a7d0>, <tensorflow.python.keras.layers.core.Dropout object at 0x7fdd93c3e9d0>, <tensorflow.python.keras.layers.merge.Add object at 0x7fdd93c0a050>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdd93c430d0>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fdd93c56150>, <tensorflow.python.keras.layers.core.Activation object at 0x7fdd93c6e8d0>, <tensorflow.python.keras.layers.convolutional.DepthwiseConv2D object at 0x7fdd93c90110>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fdd93e71790>, <tensorflow.python.keras.layers.core.Activation object at 0x7fdd93ed1050>, <tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D object at 0x7fdd93cf3f10>, <tensorflow.python.keras.layers.core.Reshape object at 0x7fdd93c6ebd0>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdd93c90bd0>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdd93c18810>, <tensorflow.python.keras.layers.merge.Multiply object at 0x7fdd93c76ed0>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdd93c06290>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fdd93c299d0>, <tensorflow.python.keras.layers.core.Dropout object at 0x7fdd93c35d10>, <tensorflow.python.keras.layers.merge.Add object at 0x7fdd93c32c50>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdd93c62310>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fdd93c32710>, <tensorflow.python.keras.layers.core.Activation object at 0x7fdd93c35d50>, <tensorflow.python.keras.layers.convolutional.DepthwiseConv2D object at 0x7fdd93bcd0d0>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fdd93c1b190>, <tensorflow.python.keras.layers.core.Activation object at 0x7fdd93bd6510>, <tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D object at 0x7fdd93bc0a50>, <tensorflow.python.keras.layers.core.Reshape object at 0x7fdd93bebed0>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdd93bebf10>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdd93be4810>, <tensorflow.python.keras.layers.merge.Multiply object at 0x7fdd93b7cb90>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdd93bf2710>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fdd93be4490>, <tensorflow.python.keras.layers.core.Dropout object at 0x7fdd93b872d0>, <tensorflow.python.keras.layers.merge.Add object at 0x7fdd93bbc650>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdd93c350d0>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fdd93b94dd0>, <tensorflow.python.keras.layers.core.Activation object at 0x7fdd93b87310>, <tensorflow.python.keras.layers.convolutional.DepthwiseConv2D object at 0x7fdd93b9e450>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fdd93b9e050>, <tensorflow.python.keras.layers.core.Activation object at 0x7fdd93ba1690>, <tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D object at 0x7fdd93b877d0>, <tensorflow.python.keras.layers.core.Reshape object at 0x7fdd93bb4b10>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdd93b941d0>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdd93b40bd0>, <tensorflow.python.keras.layers.merge.Multiply object at 0x7fdd93b409d0>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdd93b40950>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fdd93bb2910>, <tensorflow.python.keras.layers.core.Dropout object at 0x7fdd93bc5090>, <tensorflow.python.keras.layers.merge.Add object at 0x7fdd93bc0790>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdd93ce6f50>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fdd93bb2a50>, <tensorflow.python.keras.layers.core.Activation object at 0x7fdd93be4a50>, <tensorflow.python.keras.layers.convolutional.DepthwiseConv2D object at 0x7fdd93b541d0>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fdd93b4f910>, <tensorflow.python.keras.layers.core.Activation object at 0x7fdd93d25250>, <tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D object at 0x7fdd93ca6cd0>, <tensorflow.python.keras.layers.core.Reshape object at 0x7fdd93b5ca50>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdd93b5c110>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdd93b78150>, <tensorflow.python.keras.layers.merge.Multiply object at 0x7fdd93b63050>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdd93ba9bd0>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fdd93b71610>, <tensorflow.python.keras.layers.core.Dropout object at 0x7fdd93b14cd0>, <tensorflow.python.keras.layers.merge.Add object at 0x7fdd93b0d690>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdd93b142d0>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fdd93b0d590>, <tensorflow.python.keras.layers.core.Activation object at 0x7fdd93b1dc10>, <tensorflow.python.keras.layers.convolutional.DepthwiseConv2D object at 0x7fdd93b22b90>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fdd93b29110>, <tensorflow.python.keras.layers.core.Activation object at 0x7fdd93b1d6d0>, <tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D object at 0x7fdd93b38890>, <tensorflow.python.keras.layers.core.Reshape object at 0x7fdd93b66a50>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdd93abe050>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdd93acf450>, <tensorflow.python.keras.layers.merge.Multiply object at 0x7fdd93b38450>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdd93ad73d0>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fdd93acb810>, <tensorflow.python.keras.layers.core.Dropout object at 0x7fdd93aeb750>, <tensorflow.python.keras.layers.merge.Add object at 0x7fdd93ae73d0>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdd93ae2ed0>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fdd93aeba50>, <tensorflow.python.keras.layers.core.Activation object at 0x7fdd93af0250>, <tensorflow.python.keras.layers.convolutional.DepthwiseConv2D object at 0x7fdd93af01d0>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fdd93a96250>, <tensorflow.python.keras.layers.core.Activation object at 0x7fdd93af0f10>, <tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D object at 0x7fdd93af2950>, <tensorflow.python.keras.layers.core.Reshape object at 0x7fdd93acb210>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdd93b35c50>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdd93a9ad50>, <tensorflow.python.keras.layers.merge.Multiply object at 0x7fdd93af2ed0>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdd93a84d90>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fdd93b71150>, <tensorflow.python.keras.layers.core.Dropout object at 0x7fdd93b16b50>, <tensorflow.python.keras.layers.merge.Add object at 0x7fdd93b29710>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdd93be4cd0>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fdd93b80350>, <tensorflow.python.keras.layers.core.Activation object at 0x7fdd93ac30d0>, <tensorflow.python.keras.layers.convolutional.DepthwiseConv2D object at 0x7fdd93c12a50>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fdd93c12ad0>, <tensorflow.python.keras.layers.core.Activation object at 0x7fdd93b2e350>, <tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D object at 0x7fdd93ac3b50>, <tensorflow.python.keras.layers.core.Reshape object at 0x7fdd93aa81d0>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdd93abb450>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdd93a3f1d0>, <tensorflow.python.keras.layers.merge.Multiply object at 0x7fdd93bb2650>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdd93a5a3d0>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fdd93a5ab50>, <tensorflow.python.keras.layers.core.Dropout object at 0x7fdd93a696d0>, <tensorflow.python.keras.layers.merge.Add object at 0x7fdd93a57d10>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdd93a6f450>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fdd93a6fd90>, <tensorflow.python.keras.layers.core.Activation object at 0x7fdd93a61d50>, <tensorflow.python.keras.layers.convolutional.DepthwiseConv2D object at 0x7fdd93a78150>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fdd93a06050>, <tensorflow.python.keras.layers.core.Activation object at 0x7fdd93a618d0>, <tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D object at 0x7fdd93a78e90>, <tensorflow.python.keras.layers.core.Reshape object at 0x7fdd93a472d0>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdd93a0e9d0>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdd93a06e90>, <tensorflow.python.keras.layers.merge.Multiply object at 0x7fdd93a2bf10>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdd93a11c90>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fdd93a697d0>, <tensorflow.python.keras.layers.core.Dropout object at 0x7fdd93a37890>, <tensorflow.python.keras.layers.merge.Add object at 0x7fdd93a6bdd0>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdd93a3b7d0>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fdd939fe810>, <tensorflow.python.keras.layers.core.Activation object at 0x7fdd93a378d0>, <tensorflow.python.keras.layers.convolutional.DepthwiseConv2D object at 0x7fdd939cff10>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fdd939cf7d0>, <tensorflow.python.keras.layers.core.Activation object at 0x7fdd939c9910>, <tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D object at 0x7fdd939c9450>, <tensorflow.python.keras.layers.core.Reshape object at 0x7fdd939df510>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdd939df150>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdd939d3090>, <tensorflow.python.keras.layers.merge.Multiply object at 0x7fdd93abba10>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdd93a14350>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fdd939df5d0>, <tensorflow.python.keras.layers.core.Dropout object at 0x7fdd93b2e050>, <tensorflow.python.keras.layers.merge.Add object at 0x7fdd939e9550>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdd93bc5910>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fdd93a3f350>, <tensorflow.python.keras.layers.core.Activation object at 0x7fdd939f6c90>, <tensorflow.python.keras.layers.convolutional.DepthwiseConv2D object at 0x7fdd9397d250>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fdd939f9d90>, <tensorflow.python.keras.layers.core.Activation object at 0x7fdd939f6050>, <tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D object at 0x7fdd939f6c10>, <tensorflow.python.keras.layers.core.Reshape object at 0x7fdd939dfa10>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdd93983810>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdd939a01d0>, <tensorflow.python.keras.layers.merge.Multiply object at 0x7fdd9398f090>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdd93a06450>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fdd939b7bd0>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdd939b7e10>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fdd939ba850>, <tensorflow.python.keras.layers.core.Activation object at 0x7fdd939bad90>, <tensorflow.python.keras.layers.convolutional.DepthwiseConv2D object at 0x7fdd9393d1d0>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fdd93946750>, <tensorflow.python.keras.layers.core.Activation object at 0x7fdd939517d0>, <tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D object at 0x7fdd939466d0>, <tensorflow.python.keras.layers.core.Reshape object at 0x7fdd93966a50>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdd93983310>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdd9395e850>, <tensorflow.python.keras.layers.merge.Multiply object at 0x7fdd9397aed0>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdd9396c850>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fdd938fed90>, <tensorflow.python.keras.layers.core.Dropout object at 0x7fdd939513d0>, <tensorflow.python.keras.layers.merge.Add object at 0x7fdd939e9fd0>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdd93908910>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fdd939145d0>, <tensorflow.python.keras.layers.core.Activation object at 0x7fdd93914590>, <tensorflow.python.keras.layers.convolutional.DepthwiseConv2D object at 0x7fdd9391e750>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fdd9395e410>, <tensorflow.python.keras.layers.core.Activation object at 0x7fdd93934f10>, <tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D object at 0x7fdd93966550>, <tensorflow.python.keras.layers.core.Reshape object at 0x7fdd93966590>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdd9391e650>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdd939ae990>, <tensorflow.python.keras.layers.merge.Multiply object at 0x7fdd93934650>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdd93992710>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fdd93983a10>, <tensorflow.python.keras.layers.core.Dropout object at 0x7fdd93b03bd0>, <tensorflow.python.keras.layers.merge.Add object at 0x7fdd939f6750>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdd93a37690>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fdd939f1210>, <tensorflow.python.keras.layers.core.Activation object at 0x7fdd9397d910>, <tensorflow.python.keras.layers.convolutional.DepthwiseConv2D object at 0x7fdd93a2d590>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fdd9391e350>, <tensorflow.python.keras.layers.core.Activation object at 0x7fdd938c2710>, <tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D object at 0x7fdd938d5110>, <tensorflow.python.keras.layers.core.Reshape object at 0x7fdd9391abd0>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdd938d9490>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdd938ec350>, <tensorflow.python.keras.layers.merge.Multiply object at 0x7fdd938d58d0>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdd938f22d0>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fdd938e6310>, <tensorflow.python.keras.layers.core.Dropout object at 0x7fdd938faad0>, <tensorflow.python.keras.layers.merge.Add object at 0x7fdd93b22bd0>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdd939f61d0>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fdd93898b10>, <tensorflow.python.keras.layers.core.Activation object at 0x7fdd938a0a10>]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBefvSexLzEJ"
      },
      "source": [
        "You should try to fine-tune a small number of top layers rather than the whole MobileNet model. In most convolutional networks, the higher up a layer is, the more specialized it is. The first few layers learn very simple and generic features that generalize to almost all types of images. As you go higher up, the features are increasingly more specific to the dataset on which the model was trained. The goal of fine-tuning is to adapt these specialized features to work with the new dataset, rather than overwrite the generic learning."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQPJWU-JLzEK"
      },
      "source": [
        "# Decide the number of layers you want to freeze and freeze them.\r\n",
        "for layer in base_model.layers[:fine_tune_at]:\r\n",
        "  layer.trainable =  False"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_2g6n8acLzEK",
        "outputId": "bd6d3168-179b-4709-b7c6-7e45e3029a7f"
      },
      "source": [
        "# compile the model again.\r\n",
        "# It is advisable to use a lower learning rate here so that updates are not too huge and the model does not overfit.\r\n",
        "# print model summary\r\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(lr=learning_rate),\r\n",
        "              loss=tf.keras.losses.CategoricalCrossentropy(),\r\n",
        "              metrics=['accuracy'])\r\n",
        "print(model.summary())"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 200, 200, 3)]     0         \n",
            "_________________________________________________________________\n",
            "sequential (Sequential)      (None, 200, 200, 3)       0         \n",
            "_________________________________________________________________\n",
            "efficientnetb7 (Functional)  (None, 7, 7, 2560)        64097687  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d (Gl (None, 2560)              0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 2560)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 3)                 7683      \n",
            "=================================================================\n",
            "Total params: 64,105,370\n",
            "Trainable params: 63,668,843\n",
            "Non-trainable params: 436,527\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KhChPAs8LzEL",
        "outputId": "93345433-f711-4414-83a7-113f2bfbe9dd"
      },
      "source": [
        "# fit the model again.\r\n",
        "total_epochs =  epochs + 100\r\n",
        "\r\n",
        "history_fine = model.fit(train_dataset,\r\n",
        "                         epochs=total_epochs,\r\n",
        "                         initial_epoch=history.epoch[-1])"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 400/500\n",
            "7/7 [==============================] - 38s 1s/step - loss: 0.4301 - accuracy: 0.8962\n",
            "Epoch 401/500\n",
            "7/7 [==============================] - 9s 1s/step - loss: 0.3850 - accuracy: 0.9020\n",
            "Epoch 402/500\n",
            "7/7 [==============================] - 9s 1s/step - loss: 0.3255 - accuracy: 0.9350\n",
            "Epoch 403/500\n",
            "7/7 [==============================] - 9s 1s/step - loss: 0.2746 - accuracy: 0.9569\n",
            "Epoch 404/500\n",
            "7/7 [==============================] - 9s 1s/step - loss: 0.2192 - accuracy: 0.9733\n",
            "Epoch 405/500\n",
            "7/7 [==============================] - 9s 1s/step - loss: 0.2139 - accuracy: 0.9256\n",
            "Epoch 406/500\n",
            "7/7 [==============================] - 9s 1s/step - loss: 0.1631 - accuracy: 0.9566\n",
            "Epoch 407/500\n",
            "7/7 [==============================] - 9s 1s/step - loss: 0.1288 - accuracy: 0.9865\n",
            "Epoch 408/500\n",
            "7/7 [==============================] - 9s 1s/step - loss: 0.1377 - accuracy: 0.9764\n",
            "Epoch 409/500\n",
            "7/7 [==============================] - 9s 1s/step - loss: 0.1370 - accuracy: 0.9552\n",
            "Epoch 410/500\n",
            "7/7 [==============================] - 9s 1s/step - loss: 0.0570 - accuracy: 1.0000\n",
            "Epoch 411/500\n",
            "7/7 [==============================] - 9s 1s/step - loss: 0.0592 - accuracy: 0.9974\n",
            "Epoch 412/500\n",
            "7/7 [==============================] - 9s 1s/step - loss: 0.0592 - accuracy: 0.9789\n",
            "Epoch 413/500\n",
            "7/7 [==============================] - 9s 1s/step - loss: 0.0589 - accuracy: 0.9964\n",
            "Epoch 414/500\n",
            "7/7 [==============================] - 9s 1s/step - loss: 0.0484 - accuracy: 0.9964\n",
            "Epoch 415/500\n",
            "7/7 [==============================] - 9s 1s/step - loss: 0.0341 - accuracy: 1.0000\n",
            "Epoch 416/500\n",
            "7/7 [==============================] - 9s 1s/step - loss: 0.0238 - accuracy: 1.0000\n",
            "Epoch 417/500\n",
            "7/7 [==============================] - 9s 1s/step - loss: 0.0232 - accuracy: 1.0000\n",
            "Epoch 418/500\n",
            "7/7 [==============================] - 9s 1s/step - loss: 0.0187 - accuracy: 0.9974\n",
            "Epoch 419/500\n",
            "7/7 [==============================] - 9s 1s/step - loss: 0.0178 - accuracy: 1.0000\n",
            "Epoch 420/500\n",
            "7/7 [==============================] - 9s 1s/step - loss: 0.0129 - accuracy: 1.0000\n",
            "Epoch 421/500\n",
            "7/7 [==============================] - 9s 1s/step - loss: 0.0119 - accuracy: 1.0000\n",
            "Epoch 422/500\n",
            "7/7 [==============================] - 9s 1s/step - loss: 0.0099 - accuracy: 1.0000\n",
            "Epoch 423/500\n",
            "7/7 [==============================] - 9s 1s/step - loss: 0.0108 - accuracy: 1.0000\n",
            "Epoch 424/500\n",
            "7/7 [==============================] - 9s 1s/step - loss: 0.0074 - accuracy: 1.0000\n",
            "Epoch 425/500\n",
            "7/7 [==============================] - 9s 1s/step - loss: 0.0085 - accuracy: 1.0000\n",
            "Epoch 426/500\n",
            "7/7 [==============================] - 9s 1s/step - loss: 0.0067 - accuracy: 1.0000\n",
            "Epoch 427/500\n",
            "7/7 [==============================] - 9s 1s/step - loss: 0.0053 - accuracy: 1.0000\n",
            "Epoch 428/500\n",
            "7/7 [==============================] - 9s 1s/step - loss: 0.0043 - accuracy: 1.0000\n",
            "Epoch 429/500\n",
            "7/7 [==============================] - 9s 1s/step - loss: 0.0075 - accuracy: 1.0000\n",
            "Epoch 430/500\n",
            "7/7 [==============================] - 9s 1s/step - loss: 0.0042 - accuracy: 1.0000\n",
            "Epoch 431/500\n",
            "7/7 [==============================] - 9s 1s/step - loss: 0.0094 - accuracy: 1.0000\n",
            "Epoch 432/500\n",
            "7/7 [==============================] - 9s 1s/step - loss: 0.0039 - accuracy: 1.0000\n",
            "Epoch 433/500\n",
            "7/7 [==============================] - 9s 1s/step - loss: 0.0114 - accuracy: 0.9932\n",
            "Epoch 434/500\n",
            "7/7 [==============================] - 9s 1s/step - loss: 0.0053 - accuracy: 1.0000\n",
            "Epoch 435/500\n",
            "7/7 [==============================] - 9s 1s/step - loss: 0.0028 - accuracy: 1.0000\n",
            "Epoch 436/500\n",
            "7/7 [==============================] - 9s 1s/step - loss: 0.0021 - accuracy: 1.0000\n",
            "Epoch 437/500\n",
            "7/7 [==============================] - 9s 1s/step - loss: 0.0021 - accuracy: 1.0000\n",
            "Epoch 438/500\n",
            "7/7 [==============================] - 9s 1s/step - loss: 0.0022 - accuracy: 1.0000\n",
            "Epoch 439/500\n",
            "7/7 [==============================] - 9s 1s/step - loss: 0.0024 - accuracy: 1.0000\n",
            "Epoch 440/500\n",
            "7/7 [==============================] - 9s 1s/step - loss: 0.0029 - accuracy: 1.0000\n",
            "Epoch 441/500\n",
            "7/7 [==============================] - 9s 1s/step - loss: 0.0018 - accuracy: 1.0000\n",
            "Epoch 442/500\n",
            "7/7 [==============================] - 9s 1s/step - loss: 0.0020 - accuracy: 1.0000\n",
            "Epoch 443/500\n",
            "7/7 [==============================] - 9s 1s/step - loss: 0.0012 - accuracy: 1.0000\n",
            "Epoch 444/500\n",
            "7/7 [==============================] - 9s 1s/step - loss: 0.0013 - accuracy: 1.0000\n",
            "Epoch 445/500\n",
            "7/7 [==============================] - 9s 1s/step - loss: 0.0018 - accuracy: 1.0000\n",
            "Epoch 446/500\n",
            "7/7 [==============================] - 9s 1s/step - loss: 0.0018 - accuracy: 1.0000\n",
            "Epoch 447/500\n",
            "7/7 [==============================] - 9s 1s/step - loss: 0.0015 - accuracy: 1.0000\n",
            "Epoch 448/500\n",
            "7/7 [==============================] - 9s 1s/step - loss: 0.0012 - accuracy: 1.0000\n",
            "Epoch 449/500\n",
            "7/7 [==============================] - 9s 1s/step - loss: 0.0012 - accuracy: 1.0000\n",
            "Epoch 450/500\n",
            "7/7 [==============================] - 9s 1s/step - loss: 0.0011 - accuracy: 1.0000\n",
            "Epoch 451/500\n",
            "7/7 [==============================] - 9s 1s/step - loss: 0.0013 - accuracy: 1.0000\n",
            "Epoch 452/500\n",
            "7/7 [==============================] - 9s 1s/step - loss: 0.0013 - accuracy: 1.0000\n",
            "Epoch 453/500\n",
            "7/7 [==============================] - 9s 1s/step - loss: 9.2367e-04 - accuracy: 1.0000\n",
            "Epoch 454/500\n",
            "7/7 [==============================] - 9s 1s/step - loss: 6.7054e-04 - accuracy: 1.0000\n",
            "Epoch 455/500\n",
            "7/7 [==============================] - 9s 1s/step - loss: 9.2525e-04 - accuracy: 1.0000\n",
            "Epoch 456/500\n",
            "7/7 [==============================] - 9s 1s/step - loss: 9.6631e-04 - accuracy: 1.0000\n",
            "Epoch 457/500\n",
            "7/7 [==============================] - 9s 1s/step - loss: 0.0011 - accuracy: 1.0000\n",
            "Epoch 458/500\n",
            "7/7 [==============================] - 9s 1s/step - loss: 8.8273e-04 - accuracy: 1.0000\n",
            "Epoch 459/500\n",
            "7/7 [==============================] - 9s 1s/step - loss: 5.8973e-04 - accuracy: 1.0000\n",
            "Epoch 460/500\n",
            "7/7 [==============================] - 9s 1s/step - loss: 4.8040e-04 - accuracy: 1.0000\n",
            "Epoch 461/500\n",
            "7/7 [==============================] - 9s 1s/step - loss: 6.5321e-04 - accuracy: 1.0000\n",
            "Epoch 462/500\n",
            "7/7 [==============================] - 9s 1s/step - loss: 5.4164e-04 - accuracy: 1.0000\n",
            "Epoch 463/500\n",
            "7/7 [==============================] - 9s 1s/step - loss: 6.3854e-04 - accuracy: 1.0000\n",
            "Epoch 464/500\n",
            "7/7 [==============================] - 9s 1s/step - loss: 6.1975e-04 - accuracy: 1.0000\n",
            "Epoch 465/500\n",
            "7/7 [==============================] - 9s 1s/step - loss: 9.1110e-04 - accuracy: 1.0000\n",
            "Epoch 466/500\n",
            "7/7 [==============================] - 9s 1s/step - loss: 6.8664e-04 - accuracy: 1.0000\n",
            "Epoch 467/500\n",
            "7/7 [==============================] - 9s 1s/step - loss: 6.8646e-04 - accuracy: 1.0000\n",
            "Epoch 468/500\n",
            "7/7 [==============================] - 9s 1s/step - loss: 5.0791e-04 - accuracy: 1.0000\n",
            "Epoch 469/500\n",
            "7/7 [==============================] - 9s 1s/step - loss: 4.0510e-04 - accuracy: 1.0000\n",
            "Epoch 470/500\n",
            "7/7 [==============================] - 9s 1s/step - loss: 3.9849e-04 - accuracy: 1.0000\n",
            "Epoch 471/500\n",
            "7/7 [==============================] - 9s 1s/step - loss: 4.2265e-04 - accuracy: 1.0000\n",
            "Epoch 472/500\n",
            "7/7 [==============================] - 9s 1s/step - loss: 4.0335e-04 - accuracy: 1.0000\n",
            "Epoch 473/500\n",
            "7/7 [==============================] - 9s 1s/step - loss: 7.0913e-04 - accuracy: 1.0000\n",
            "Epoch 474/500\n",
            "7/7 [==============================] - 9s 1s/step - loss: 3.2832e-04 - accuracy: 1.0000\n",
            "Epoch 475/500\n",
            "7/7 [==============================] - 9s 1s/step - loss: 5.5152e-04 - accuracy: 1.0000\n",
            "Epoch 476/500\n",
            "7/7 [==============================] - 9s 1s/step - loss: 3.2539e-04 - accuracy: 1.0000\n",
            "Epoch 477/500\n",
            "7/7 [==============================] - 9s 1s/step - loss: 2.9246e-04 - accuracy: 1.0000\n",
            "Epoch 478/500\n",
            "7/7 [==============================] - 9s 1s/step - loss: 6.8521e-04 - accuracy: 1.0000\n",
            "Epoch 479/500\n",
            "7/7 [==============================] - 9s 1s/step - loss: 4.4676e-04 - accuracy: 1.0000\n",
            "Epoch 480/500\n",
            "7/7 [==============================] - 9s 1s/step - loss: 2.7990e-04 - accuracy: 1.0000\n",
            "Epoch 481/500\n",
            "7/7 [==============================] - 9s 1s/step - loss: 4.2740e-04 - accuracy: 1.0000\n",
            "Epoch 482/500\n",
            "7/7 [==============================] - 9s 1s/step - loss: 4.3498e-04 - accuracy: 1.0000\n",
            "Epoch 483/500\n",
            "7/7 [==============================] - 9s 1s/step - loss: 2.8417e-04 - accuracy: 1.0000\n",
            "Epoch 484/500\n",
            "7/7 [==============================] - 9s 1s/step - loss: 2.4399e-04 - accuracy: 1.0000\n",
            "Epoch 485/500\n",
            "7/7 [==============================] - 9s 1s/step - loss: 3.2155e-04 - accuracy: 1.0000\n",
            "Epoch 486/500\n",
            "7/7 [==============================] - 9s 1s/step - loss: 3.7262e-04 - accuracy: 1.0000\n",
            "Epoch 487/500\n",
            "7/7 [==============================] - 9s 1s/step - loss: 4.7551e-04 - accuracy: 1.0000\n",
            "Epoch 488/500\n",
            "7/7 [==============================] - 9s 1s/step - loss: 2.8643e-04 - accuracy: 1.0000\n",
            "Epoch 489/500\n",
            "7/7 [==============================] - 9s 1s/step - loss: 4.2221e-04 - accuracy: 1.0000\n",
            "Epoch 490/500\n",
            "7/7 [==============================] - 9s 1s/step - loss: 2.6518e-04 - accuracy: 1.0000\n",
            "Epoch 491/500\n",
            "7/7 [==============================] - 9s 1s/step - loss: 4.5533e-04 - accuracy: 1.0000\n",
            "Epoch 492/500\n",
            "7/7 [==============================] - 9s 1s/step - loss: 3.5588e-04 - accuracy: 1.0000\n",
            "Epoch 493/500\n",
            "7/7 [==============================] - 9s 1s/step - loss: 2.1365e-04 - accuracy: 1.0000\n",
            "Epoch 494/500\n",
            "7/7 [==============================] - 9s 1s/step - loss: 2.1442e-04 - accuracy: 1.0000\n",
            "Epoch 495/500\n",
            "7/7 [==============================] - 9s 1s/step - loss: 1.6431e-04 - accuracy: 1.0000\n",
            "Epoch 496/500\n",
            "7/7 [==============================] - 9s 1s/step - loss: 3.3939e-04 - accuracy: 1.0000\n",
            "Epoch 497/500\n",
            "7/7 [==============================] - 9s 1s/step - loss: 3.3129e-04 - accuracy: 1.0000\n",
            "Epoch 498/500\n",
            "7/7 [==============================] - 9s 1s/step - loss: 2.0819e-04 - accuracy: 1.0000\n",
            "Epoch 499/500\n",
            "7/7 [==============================] - 9s 1s/step - loss: 1.8219e-04 - accuracy: 1.0000\n",
            "Epoch 500/500\n",
            "7/7 [==============================] - 9s 1s/step - loss: 2.8128e-04 - accuracy: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EyGUJo7jLzEL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 591
        },
        "outputId": "fdc36262-bf47-4ae4-acb8-63962654f666"
      },
      "source": [
        "# plot the loss and accuracy curves again\r\n",
        "model_path = os.path.join(os.getcwd(),\"model2\")\r\n",
        "model.save(model_path)\r\n",
        "hist_fine_acc = history_fine.history['accuracy']\r\n",
        "hist_fine_loss = history_fine.history['loss']\r\n",
        "plt.plot( hist_fine_loss)\r\n",
        "plt.title('model loss')\r\n",
        "plt.ylabel('loss')\r\n",
        "plt.xlabel('epoch')\r\n",
        "plt.show()\r\n",
        "plt.plot( hist_fine_acc )\r\n",
        "plt.title('model accuracy')\r\n",
        "plt.ylabel('accuracy')\r\n",
        "plt.xlabel('epoch')\r\n",
        "plt.show()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/model2/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JjaSPKstLzEM"
      },
      "source": [
        "### Prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ZpCd8RpLzEM"
      },
      "source": [
        "Now we will use our model to make predictions on test set. Store the predictions like in sample_submission.csv file. \r\n",
        "\r\n",
        "sample_submission.csv\r\n",
        "- 4 columns\r\n",
        "- 1 row for each test image (total 853 rows)\r\n",
        "- 1st column = image file name\r\n",
        "- 2nd column = probability of the given image being qingqi\r\n",
        "- 3rd column = probability of the given image being rickshaw\r\n",
        "- 4th column = probability of the given image being tanga"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fwZO_I3k28Z-"
      },
      "source": [
        "\r\n",
        "def test_img_label_generator(filepaths,input_shape):\r\n",
        "  images = []\r\n",
        "  for filepath in filepaths:\r\n",
        "    img = cv2.imread(filepath)\r\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\r\n",
        "    img = img / 255.0\r\n",
        "    img = resize(img, input_shape, preserve_range=True)\r\n",
        "    yield img\r\n",
        "def test_batch_data_generator(filepaths = [],input_shape = (256,256,3),batch_size = 32):\r\n",
        "  running = True\r\n",
        "  while running:\r\n",
        "    img_batch = []\r\n",
        "    gen = test_img_label_generator(filepaths,input_shape)\r\n",
        "    for img in tqdm(gen):\r\n",
        "      img_batch.append(img)\r\n",
        "      if len(img_batch) == batch_size:\r\n",
        "        yield np.stack(img_batch,axis = 0)\r\n",
        "        img_batch = []\r\n",
        "      if len(img_batch) != 0:\r\n",
        "        yield np.stack(img_batch,axis = 0)\r\n",
        "        img_batch = []\r\n",
        "        "
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iiRvX69VLzEP"
      },
      "source": [
        "# Read and preprocess test data. Remeber to store the names of image files\r\n",
        "qingqi_preds,rickshaw_preds,tanga_preds = [],[],[]\r\n",
        "for path in testing_paths:\r\n",
        "  img = keras.preprocessing.image.load_img(\r\n",
        "    path, target_size=input_shape +(3,)\r\n",
        "  )\r\n",
        "  img_array = keras.preprocessing.image.img_to_array(img)\r\n",
        "  img_array = tf.expand_dims(img_array, 0)  \r\n",
        "  predictions = model.predict(img_array)\r\n",
        "  qingqi = predictions[0][0]\r\n",
        "  rickshaw = predictions[0][1]\r\n",
        "  tanga = predictions[0][2]\r\n",
        "  qingqi_preds.append(qingqi)\r\n",
        "  rickshaw_preds.append(rickshaw)\r\n",
        "  tanga_preds.append(tanga)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KSlKnAfJLzEP"
      },
      "source": [
        "# store the predictions in a .csv file like in sample_submission.csv (Hint: pandas may be helpful here)\r\n",
        "import pandas as pd\r\n",
        "test_filenames = [f.split(\"/\")[-1].split(\".jpg\")[0] for f in testing_paths]\r\n",
        "data = {'id': test_filenames, 'qingqi':qingqi_preds, 'rickshaw': rickshaw_preds,'tanga':tanga_preds}\r\n",
        "df = pd.DataFrame(data = data)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tmPXfjwxLzEQ"
      },
      "source": [
        "df.to_csv(\"submission.csv\",index= False)"
      ],
      "execution_count": 30,
      "outputs": []
    }
  ]
}